{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import IPython\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "os.chdir(\"F:\\M2\\Interpretable-TimeSeries-Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melvi\\AppData\\Local\\Temp\\ipykernel_2880\\2820360306.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  music_time_series, sr = librosa.load(dataloc + genre + \"/\" + music)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading jazz.00054.wav: \n",
      "Creating dataframe\n",
      "Saving dataframe\n",
      "Saving train and test data\n"
     ]
    }
   ],
   "source": [
    "dataloc  = \"Data/genres_original/\"\n",
    "\n",
    "genres = os.listdir(dataloc)\n",
    "\n",
    "musiclist = []\n",
    "genrelist = []\n",
    "srlist = []\n",
    "\n",
    "musictrain = []\n",
    "genretrain = []\n",
    "srtrain = []\n",
    "musictest = []\n",
    "genretest = []\n",
    "srtest = []\n",
    "\n",
    "print(\"Reading songs\")\n",
    "for genre in genres:\n",
    "    for i, music in enumerate(os.listdir(dataloc + genre)):\n",
    "        try:\n",
    "            music_time_series, sr = librosa.load(dataloc + genre + \"/\" + music)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {music}: {e}\")\n",
    "            continue\n",
    "        srlist.append(sr)\n",
    "        musiclist.append(music_time_series)\n",
    "        genrelist.append(genre)\n",
    "\n",
    "        if i<25: # 25-75 test train split\n",
    "            musictest.append(music_time_series)\n",
    "            genretest.append(genre)\n",
    "            srtest.append(sr)\n",
    "        else:\n",
    "            musictrain.append(music_time_series)\n",
    "            genretrain.append(genre)\n",
    "            srtrain.append(sr)\n",
    "\n",
    "print(\"Creating dataframe\")\n",
    "fulldata = pd.DataFrame({'Music': musiclist, 'Genre': genrelist, \"SampleRate\": srlist})\n",
    "\n",
    "print(\"Saving dataframe\")\n",
    "fulldata.to_csv(\"Data/fulldata.csv\", index=False)\n",
    "\n",
    "print(\"Saving train and test data\")\n",
    "train = pd.DataFrame({\"Music\" : musictrain, \"Genre\" : genretrain, \"SampleRate\": srtrain})\n",
    "test = pd.DataFrame({\"Music\" : musictest, \"Genre\" : genretest, \"SampleRate\": srtest})\n",
    "\n",
    "with open(\"Data/train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train, f)\n",
    "\n",
    "with open(\"Data/test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/train.pkl\", \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(\"Data/test.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAX Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = np.array([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"])\n",
    "\n",
    "def SAX(time_series, w, alpha):\n",
    "    time_series = np.array(time_series)\n",
    "    time_series = (time_series - np.mean(time_series)) / np.std(time_series)\n",
    "\n",
    "    # PAA\n",
    "    PAA=[]\n",
    "    for word_index in range(w):\n",
    "        ceiling = min(len(time_series), int((word_index+1)*len(time_series)/w))\n",
    "        PAA.append(np.mean(time_series[int(word_index*len(time_series)/w):ceiling]))\n",
    "    \n",
    "    lookup = np.quantile(time_series, np.arange(1,alpha)*(1/alpha) )\n",
    "    \n",
    "    sax = np.digitize(PAA, lookup)\n",
    "\n",
    "    return list(sax)\n",
    "\n",
    "def SAX_window(time_series, w, alpha, l):\n",
    "    L = len(time_series)\n",
    "    sax_sentence = []\n",
    "    previous_word = np.full(w,-1)\n",
    "\n",
    "    for i in range(0, (L-l+1), l//2):\n",
    "        ceiling = min(L, (i+1)*l)\n",
    "        sax_word = SAX(time_series[i : ceiling], w, alpha)\n",
    "\n",
    "        npsaxword = np.array(sax_word)\n",
    "        if np.sum(npsaxword - previous_word) == 0: # Remove repeated words for reasons\n",
    "            continue\n",
    "        \n",
    "        if i > 0:\n",
    "            sax_sentence.append(\" \")\n",
    "        sax_sentence.extend(sax_word)\n",
    "        previous_word = sax_word\n",
    "\n",
    "    phrase = \"\"\n",
    "    for letter in sax_sentence:\n",
    "        if isinstance(letter, np.int64):\n",
    "            phrase += alphabet[letter]\n",
    "        else :\n",
    "            phrase += letter\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried a parallelized version for increment 1, gets OOM\n",
    "\"\"\"def SAX_window(time_series, w, alpha, l):\n",
    "    L = len(time_series)\n",
    "    sax_sentence = []\n",
    "    previous_word = np.full(w,-1)\n",
    "\n",
    "    all_windows= np.empty((l,L - l + 1))\n",
    "    for i in range(0, L-l+1):\n",
    "        print(i)\n",
    "        ceiling = i+l\n",
    "        all_windows[i] = time_series[i : ceiling]\n",
    "\n",
    "    allsax = np.apply_along_axis(SAX, 0, all_windows)\n",
    "    print(allsax.shape)\n",
    "\n",
    "    phrase = \"\"\n",
    "    for letter in sax_sentence:\n",
    "        if isinstance(letter, np.int64):\n",
    "            phrase += alphabet[letter]\n",
    "        else :\n",
    "            phrase += letter\n",
    "    return phrase\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccccbccccccbcbcb cccccccccccccccc cccccccbcccccccc cccccccccccccccc cbcccccccccccccc cccccccccccccbbb\n"
     ]
    }
   ],
   "source": [
    "nptrainmusic = train[\"Music\"].to_numpy()\n",
    "\n",
    "selected_index = 81\n",
    "selected_music = nptrainmusic[selected_index]\n",
    "\n",
    "# Pre-process eliminating noise\n",
    "#testmusic = librosa.effects.preemphasis(testmusic)\n",
    "\n",
    "sentence = SAX_window(selected_music, w = 16, alpha = 4, l = int(.2*len(selected_music)+1 ))\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 4\n",
    "w , halfw= 4, 2\n",
    "\n",
    "DFT_base_length4 = np.empty((len(nptrainmusic), w))\n",
    "\n",
    "for i, music in enumerate(nptrainmusic):\n",
    "    fft = np.fft.fft(music)\n",
    "    halfw_real = np.real(fft[:halfw])\n",
    "    halfw_complex = np.imag(fft[:halfw])\n",
    "    \n",
    "    DFT_base_length4[i] = np.array([halfw_real[0], halfw_complex[0], halfw_real[1], halfw_complex[1]]) # Shitty inefficient, can be made with np.apply_along_axis\n",
    "\n",
    "q =  np.arange(1,alpha)*(1/alpha)\n",
    "\n",
    "SFA_breakpoints = np.quantile(DFT_base_length4, q, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSFA\u001b[39m(time_series, alpha\u001b[38;5;241m=\u001b[39m\u001b[43malpha\u001b[49m, w\u001b[38;5;241m=\u001b[39mw, lookup\u001b[38;5;241m=\u001b[39mSFA_breakpoints):\n\u001b[0;32m      2\u001b[0m     fft \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mfft(time_series)\n\u001b[0;32m      3\u001b[0m     halfw \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "def SFA(time_series, alpha=alpha, w=w, lookup=SFA_breakpoints):\n",
    "    fft = np.fft.fft(time_series)\n",
    "    halfw = w//2\n",
    "    halfw_real = np.real(fft[:halfw])\n",
    "    halfw_complex = np.imag(fft[:halfw])\n",
    "    coefs = np.array([halfw_real[0], halfw_complex[0], halfw_real[1], halfw_complex[1]])\n",
    "\n",
    "    sfa=np.empty(w, dtype=np.int64)\n",
    "    for i, coef in enumerate(coefs):\n",
    "        sfa[i] = np.digitize(coef, lookup[:,i]) * (i+1) # *(i+1) to make sure same indices for different coefficients don't get the same symbol\n",
    "\n",
    "    return sfa\n",
    "\n",
    "def SFA_window(time_series, l, alpha=alpha, w=w, lookup=SFA_breakpoints):\n",
    "    L = len(time_series)\n",
    "    sfa_sentence = []\n",
    "    previous_word = np.full(w,-1)\n",
    "\n",
    "    for i in range(0, L, l): # Non-overlapping windows for this one\n",
    "        ceiling = min(L, (i+1)*l) \n",
    "        sfa_word = SFA(time_series[i : ceiling], w, alpha, lookup=lookup)\n",
    "\n",
    "        npsfaword = np.array(sfa_word)\n",
    "        if np.sum(npsfaword - previous_word) == 0: # Remove repeated words for reasons\n",
    "            continue\n",
    "        \n",
    "        if i > 0:\n",
    "            sfa_sentence.append(\" \")\n",
    "        sfa_sentence.extend(sfa_word)\n",
    "        previous_word = sfa_word\n",
    "\n",
    "    phrase = \"\"\n",
    "    for letter in sfa_sentence:\n",
    "        if isinstance(letter, np.int64):\n",
    "            phrase += alphabet[letter]\n",
    "        elif letter == \" \":\n",
    "            phrase += letter\n",
    "        else:\n",
    "            raise ValueError(\"error, got letter\", letter)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dagi dgdi dagi dedi dede dege\n"
     ]
    }
   ],
   "source": [
    "selected_index = 162\n",
    "selected_music = nptrainmusic[selected_index]\n",
    "\n",
    "print(SFA_window(selected_music, l=int(.2*len(selected_music+1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEQL:\n",
    "    def __init__(self, C=1.0, alpha=0.5, convergence_threshold=1e-5, max_iterations=1000):\n",
    "        self.C = C\n",
    "        self.alpha = alpha\n",
    "        self.convergence_threshold = convergence_threshold\n",
    "        self.max_iterations = max_iterations\n",
    "        self.beta = None\n",
    "        self.best_feature = None\n",
    "        self.index_to_feature = []\n",
    "        self.bigX = []\n",
    "\n",
    "    def _compute_regularization_gradient(self, beta):\n",
    "        \"\"\"Elastic-net gradient.\"\"\"\n",
    "        return self.alpha * np.sign(beta) + (1 - self.alpha) * beta\n",
    "\n",
    "    def _compute_loss_gradient(self, X, y, beta):\n",
    "        \"\"\"Compute gradients for all features.\"\"\"\n",
    "        margins = y * (X @ beta)\n",
    "        probabilities = -1 / (1 + np.exp(margins))\n",
    "        gradients = X.T @ (y * probabilities) / len(y)\n",
    "        return gradients\n",
    "    \n",
    "    def _line_search(self, X, y, beta, gradients, best_gradient_index):\n",
    "        \"\"\"Perform a line search to find the optimal step size for updating beta.\"\"\"\n",
    "        old_margins = y * (X @ beta)\n",
    "        old_loss = np.mean(np.log(1 + np.exp(-old_margins))) + self.C * (\n",
    "            self.alpha * np.sum(np.abs(beta)) + (1 - self.alpha) * 0.5 * np.sum(beta ** 2)\n",
    "        )\n",
    "\n",
    "        step_size = 1.0\n",
    "        while step_size > 1e-10:\n",
    "            new_beta = beta.copy()\n",
    "            new_beta[best_gradient_index] -= step_size * gradients[best_gradient_index]\n",
    "            new_margins = y * (X @ new_beta)\n",
    "            new_loss = np.mean(np.log(1 + np.exp(-new_margins))) + self.C * (\n",
    "                self.alpha * np.sum(np.abs(new_beta)) + (1 - self.alpha) * 0.5 * np.sum(new_beta ** 2)\n",
    "            )\n",
    "            \n",
    "            if new_loss <= old_loss + 1e-10:\n",
    "                return step_size\n",
    "            step_size *= 0.5\n",
    "        \n",
    "        print(\"Failed line search\")\n",
    "        return 1e-10  # Return a small constant to prevent zero step size\n",
    "    \n",
    "\n",
    "\n",
    "    def fit(self, representations, y, nb_classes = False, plot_grads = False, verbose = False):\n",
    "        \"\"\"\n",
    "        representations : symbolic representations of the whole training set using the same discretization method and parameters\n",
    "        y : labels to predict\n",
    "        \"\"\"\n",
    "        if not nb_classes:\n",
    "            nb_classes = max(y)+1\n",
    "        y_one_hot = np.zeros((len(y), nb_classes))\n",
    "        y_one_hot[np.arange(len(y)), y] = 1\n",
    "\n",
    "        # Extract unigrams from the representations\n",
    "        feature_map = {char: idx for idx, char in enumerate(set(''.join(representations).replace(' ', '')))} # initialize unigrams and their ID\n",
    "        map_features = [char for char in feature_map.keys()]\n",
    "        nb_new_features = len(feature_map)\n",
    "\n",
    "        # Initialize feature matrix\n",
    "        X = np.zeros((len(representations), len(feature_map)))\n",
    "\n",
    "        # Build initial feature matrix\n",
    "        for i, seq in enumerate(representations):\n",
    "            for feature in feature_map:\n",
    "                X[i, feature_map[feature]] = seq.count(feature)\n",
    "\n",
    "        num_features = X.shape[1]\n",
    "        self.beta = np.zeros(num_features)\n",
    "\n",
    "        if plot_grads: best_grads=[]\n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            #Compute gradients\n",
    "            loss_gradients = self._compute_loss_gradient(X, y, self.beta) \n",
    "            regu_gradients = self._compute_regularization_gradient(self.beta) * self.C\n",
    "            gradients = loss_gradients + regu_gradients\n",
    "\n",
    "            best_gradient = np.max(abs(gradients))\n",
    "            best_gradient_index = np.argmax(abs(gradients))\n",
    "            best_grads.append(best_gradient)\n",
    "\n",
    "            if np.sum(X[:, best_gradient_index]) == 0: #If the feature is not present in the dataset\n",
    "                print(\"Problem at iteration\", iteration)\n",
    "                print(\"Best gradient :\", best_gradient)\n",
    "                print(\"Sum gradients :\", gradients.sum()) \n",
    "                raise ValueError(\"Best feature not present in dataset\")\n",
    "\n",
    "            if verbose : print(\"Iteration\",iteration,\", best gradient :\", best_gradient)\n",
    "\n",
    "            #Stopping condition\n",
    "            if best_gradient < self.convergence_threshold :\n",
    "                break\n",
    "\n",
    "            #Expand features\n",
    "            new_features = set()\n",
    "\n",
    "            for feature_idx in range(num_features-1, num_features- nb_new_features-1, -1): #Only extend features added during last iteration\n",
    "                subseq = map_features[feature_idx]\n",
    "                for seq in representations[X[:,feature_idx] > 0]: #Only consider sequences where the feature is present\n",
    "                    found = seq.find(subseq)\n",
    "                    while found>=0:\n",
    "                        if found + len(subseq) + 1 >= len(seq): #Don't cross over the end of the sequence\n",
    "                            break\n",
    "\n",
    "                        newchar = seq[found + len(subseq) + 1]\n",
    "                        if newchar != ' ': #Don't cross over several words\n",
    "                            new_features.add(subseq+newchar)\n",
    "\n",
    "                        found = seq.find(subseq, found+1)\n",
    "                        \n",
    "            if verbose : print(\"Number of new features:\", len(new_features))\n",
    "\n",
    "            #Prune\n",
    "            upper_bounds = []\n",
    "            checked_prefixes = [False] * len(feature_map)\n",
    "            for new_feature in new_features:\n",
    "                prefix_index = feature_map[new_feature[:-1]]\n",
    "\n",
    "                if checked_prefixes[prefix_index]:\n",
    "                    upper_bounds.append(checked_prefixes[prefix_index])\n",
    "                    continue\n",
    "\n",
    "                prefix_appearances = X[:, prefix_index] > 1e-10 #indices where the prefix is present\n",
    "                \n",
    "                boundmax = 0\n",
    "                for classe in [-1,1]:\n",
    "                    check_indices = (prefix_appearances * y==classe)\n",
    "                    bound = np.sum((-classe * 1/(1+np.exp(classe * X[check_indices, :] @ self.beta)))) \n",
    "                    bound+= regu_gradients[prefix_index]\n",
    "                    bound = abs(bound)\n",
    "                    if bound > boundmax:\n",
    "                        boundmax = bound\n",
    "\n",
    "                upper_bounds.append(boundmax)\n",
    "                checked_prefixes[prefix_index] = boundmax\n",
    "            \n",
    "            prune = upper_bounds <= best_gradient\n",
    "            nb_new_features = len(new_features) - np.sum(prune)\n",
    "\n",
    "            for i,feature in enumerate(new_features):\n",
    "                if prune[i]: continue\n",
    "                map_features.append(feature)\n",
    "                feature_map[feature] = len(feature_map)\n",
    "\n",
    "            num_features = len(feature_map)\n",
    "            new_X = np.zeros((len(representations), nb_new_features)) # There is a way to do feature expansion, pruning and X update all within the same loop, do later\n",
    "            X = np.block([X, new_X])\n",
    "            \n",
    "            nb_previous_features = num_features - nb_new_features\n",
    "            for i, seq in enumerate(representations):\n",
    "                nonpruned=0\n",
    "                for j, feature in enumerate(new_features):\n",
    "                    if prune[j]: continue\n",
    "                    X[i, nb_previous_features+nonpruned ] = seq.count(feature)\n",
    "                    nonpruned+=1\n",
    "            \n",
    "            self.beta = np.append(self.beta, np.zeros(nb_new_features)) # Add 0 coefs to new features\n",
    "            step_size = self._line_search(X, y, self.beta, gradients, best_gradient_index) \n",
    "            self.beta[best_gradient_index] -= step_size * gradients[best_gradient_index] # Update beta\n",
    "\n",
    "            if verbose : \n",
    "                print(\"Number of features after pruning:\", X.shape[1],\",\",np.sum(prune),\"features pruned\")\n",
    "                print(\"Gradient Upper bounds :\", upper_bounds)\n",
    "\n",
    "        #Append selected features to selected features list\n",
    "        self.index_to_feature.extend(map_features)\n",
    "        \n",
    "        if not len(self.bigX):\n",
    "            self.bigX = X\n",
    "        else :\n",
    "            self.bigX = np.block([self.bigX, X])\n",
    "\n",
    "        if plot_grads:\n",
    "            plt.title(\"Best gradient per iteration\")\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.ylabel(\"Best gradient\")\n",
    "            plt.plot(best_grads)\n",
    "            plt.grid('yes')\n",
    "            plt.show()\n",
    "\n",
    "    def predict(self, representations):\n",
    "        # Build feature matrix\n",
    "        X = np.zeros((len(representations), len(self.index_to_feature)))\n",
    "        for i, seq in enumerate(representations):\n",
    "            for feature in self.index_to_feature:\n",
    "                X[i, self.index_to_feature.index(feature)] = seq.count(feature)\n",
    "\n",
    "        return np.sign(X @ self.beta)\n",
    "    \n",
    "    def predict_probas(self, representations):\n",
    "        # Build feature matrix\n",
    "        X = np.zeros((len(representations), len(self.index_to_feature)))\n",
    "        for i, seq in enumerate(representations):\n",
    "            for feature in self.index_to_feature:\n",
    "                X[i, self.index_to_feature.index(feature)] = seq.count(feature)\n",
    "\n",
    "        return X @ self.beta\n",
    "    \n",
    "    def score(self, representations, y):\n",
    "        return np.mean(self.predict(representations) == y)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (569, 30)\n",
      "Labels shape: (569,)\n",
      "First 5 labels: [-1 -1 -1 -1 -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "\n",
    "y = data.target\n",
    "# Convert labels from {0, 1} to {-1, 1}\n",
    "y = 2 * y - 1\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n",
    "print(\"First 5 labels:\", y[:5])\n",
    "\n",
    "cancer_sax = np.array([SAX_window(ts, w=16, alpha=4, l = int(0.2*len(ts))+1 ) for ts in X_train])\n",
    "cancer_sax_test = np.array([SAX_window(ts, w=16, alpha=4, l = int(0.2*len(ts))+1 ) for ts in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 , best gradient : 6.097417840375587\n",
      "Number of new features: 16\n",
      "Number of features after pruning: 20 , 0 features pruned\n",
      "Gradient Upper bounds : [134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0]\n",
      "Iteration 1 , best gradient : 1.2929124263856098\n",
      "Number of new features: 64\n",
      "Number of features after pruning: 84 , 0 features pruned\n",
      "Gradient Upper bounds : [102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 101.26079138576682, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 68.27288143792234, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 68.27288143792234, 68.27288143792234, 102.56089593707077, 101.26079138576682, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 102.56089593707077, 101.26079138576682, 102.56089593707077, 102.56089593707077, 101.26079138576682, 102.56089593707077, 102.56089593707077, 102.56089593707077, 68.27288143792234, 102.56089593707077, 102.56089593707077, 102.56089593707077]\n",
      "Iteration 2 , best gradient : 0.5694702239455989\n",
      "Number of new features: 205\n",
      "Number of features after pruning: 289 , 0 features pruned\n",
      "Gradient Upper bounds : [44.59077504584087, 97.8300497811585, 103.22862379508348, 0.7696351727495525, 6.953543181131957, 98.95536167194527, 102.07416648178693, 96.5504343747971, 102.44552297869608, 103.22862379508348, 86.64978348508784, 92.83491651632477, 97.78079920204758, 87.91345720732298, 71.20808754072775, 60.055077783319824, 44.59077504584087, 92.83491651632477, 96.54154885653344, 103.22862379508348, 98.6108036502417, 98.63078426974403, 96.5504343747971, 8.490447536490937, 56.90554201467903, 52.55419477562753, 55.05778519274151, 103.22862379508348, 98.6108036502417, 103.22862379508348, 98.97994601191681, 103.22862379508348, 8.490447536490937, 16.63422809833167, 102.08749931335467, 102.84824896784055, 97.78079920204758, 39.64489236011808, 102.08749931335467, 18.56490010332473, 98.95783149682809, 97.17005954755416, 102.078613795091, 4.662408699410638, 2.6981940149356642, 81.01796424228874, 16.63422809833167, 103.22862379508348, 98.95783149682809, 95.10056195754981, 60.055077783319824, 74.96296546079384, 98.6108036502417, 98.95783149682809, 97.17005954755416, 3.834833097688548, 47.584861385223434, 100.55042944248606, 14.96800908506598, 100.54156751931743, 94.33545313176367, 97.78079920204758, 103.22862379508348, 102.08749931335467, 6.953543181131957, 66.92399751945133, 92.83491651632477, 103.22862379508348, 47.584861385223434, 6.953543181131957, 87.91345720732298, 100.55042944248606, 55.68406270569225, 16.63422809833167, 102.44552297869608, 94.33545313176367, 18.56490010332473, 11.173141778641146, 3.0852211823722744, 71.20808754072775, 96.54154885653344, 95.10056195754981, 52.55419477562753, 0.7696351727495525, 93.46342720734549, 98.95536167194527, 81.01796424228874, 93.46342720734549, 98.95536167194527, 97.78079920204758, 24.279388987396583, 14.96800908506598, 103.22862379508348, 103.22862379508348, 35.39731012696559, 32.31167395588079, 71.20808754072775, 52.43619078676778, 84.4657991498681, 71.20808754072775, 3.0852211823722744, 102.078613795091, 3.834833097688548, 4.662408699410638, 11.173141778641146, 102.07416648178693, 102.07416648178693, 100.54156751931743, 100.55042944248606, 84.58792947052068, 86.64978348508784, 8.490447536490937, 102.44552297869608, 98.97994601191681, 102.84824896784055, 98.6108036502417, 103.22862379508348, 93.46342720734549, 35.39731012696559, 98.63078426974403, 86.64978348508784, 102.44552297869608, 103.22862379508348, 103.22862379508348, 102.06972827682733, 84.58792947052068, 94.33545313176367, 97.17005954755416, 66.92399751945133, 27.26350760131057, 103.22862379508348, 98.63078426974403, 97.8300497811585, 24.279388987396583, 103.22862379508348, 93.46342720734549, 98.97994601191681, 56.90554201467903, 39.64489236011808, 103.22862379508348, 56.90554201467903, 55.05778519274151, 56.90554201467903, 103.22862379508348, 87.91345720732298, 92.83491651632477, 60.055077783319824, 103.22862379508348, 27.26350760131057, 32.31167395588079, 103.22862379508348, 95.10056195754981, 103.22862379508348, 8.490447536490937, 52.43619078676778, 4.662408699410638, 96.54154885653344, 103.22862379508348, 86.64978348508784, 102.06972827682733, 98.63078426974403, 103.22862379508348, 14.96800908506598, 55.68406270569225, 95.10056195754981, 97.78079920204758, 103.22862379508348, 97.17005954755416, 87.91345720732298, 81.01796424228874, 97.78079920204758, 55.68406270569225, 103.22862379508348, 100.54156751931743, 97.78079920204758, 24.279388987396583, 44.59077504584087, 97.78079920204758, 97.8300497811585, 97.8300497811585, 102.07416648178693, 55.05778519274151, 2.6981940149356642, 102.078613795091, 96.54154885653344, 74.96296546079384, 35.39731012696559, 94.33545313176367, 3.0852211823722744, 102.078613795091, 84.58792947052068, 96.5504343747971, 102.06972827682733, 102.84824896784055, 98.95536167194527, 52.43619078676778, 97.78079920204758, 52.43619078676778, 103.22862379508348, 60.055077783319824, 18.56490010332473, 103.22862379508348, 55.05778519274151, 18.56490010332473, 97.78079920204758]\n",
      "Iteration 3 , best gradient : 4.475432525232816\n",
      "Number of new features: 313\n",
      "Number of features after pruning: 533 , 69 features pruned\n",
      "Gradient Upper bounds : [49.85919358085994, 93.92060186136626, 1.8299136845961028, 107.42158762541912, 103.18088292969541, 16.01312585225436, 15.87117921987176, 53.162323768804136, 99.44438045666442, 1.8299136845961028, 109.38577716068093, 15.937847398474167, 0.26688028824389387, 29.42673265076175, 104.09843682518797, 10.842862537444471, 86.05719599185211, 109.38577716068093, 10.803491175459873, 102.16974519255876, 27.157695484893587, 0.6418507816881137, 1.413315546107559, 19.197759455489205, 16.01312585225436, 26.449374970375395, 46.34803498386791, 1.9055049931368127, 0.28103670376585, 58.71112343704222, 109.38577716068093, 109.38577716068093, 100.59115089069623, 109.38577716068093, 0.3158969107294314, 84.70461501830042, 42.14037933945084, 8.45942436375074, 107.34306793538696, 41.552223900940845, 56.630463341090376, 29.42673265076175, 95.32541133731154, 11.090013176125291, 3.6358845410386653, 102.16974519255876, 96.10632165160465, 2.26875145647812, 61.87994341004333, 6.630322420490897, 96.38994924781468, 89.40126982187795, 4.9519874560695945, 2.5223533203266673, 84.70461501830042, 0.7140345291460718, 2.1187805486665026, 3.618624181573708, 41.552223900940845, 106.42357829557568, 107.85628248875608, 26.449374970375395, 87.30496993130771, 19.42902860348388, 89.3376556010071, 96.10632165160465, 107.85628248875608, 2.5223533203266673, 103.82273371138353, 109.38577716068093, 58.71112343704222, 6.942520522485059, 75.19172487578095, 0.7624321670583768, 102.91832955019052, 0.26688028824389387, 14.682314307035973, 104.09843682518797, 109.38577716068093, 6.630322420490897, 1.660796969756083, 107.34306793538696, 41.34515814495717, 6.914484720189929, 106.57432399615672, 19.197759455489205, 1.4089618723416837, 34.97496259919305, 2.116873519739171, 34.97496259919305, 51.37942665646378, 78.21235661207038, 3.618624181573708, 0.7624321670583768, 107.34306793538696, 7.510737577002377, 56.630463341090376, 32.62531429859034, 71.60136415716836, 9.461488857322204, 41.34515814495717, 53.162323768804136, 47.75142191413015, 58.71112343704222, 99.44438045666442, 94.42633749387565, 0.28103670376585, 87.44763113117196, 9.389768475957432, 29.42673265076175, 103.18088292969541, 106.44296694264851, 11.366012679870012, 9.952222871491253, 109.38577716068093, 103.18088292969541, 49.85919358085994, 14.716590941682917, 13.966644159033057, 109.38577716068093, 41.354617433402574, 32.62531429859034, 61.480663666346395, 109.38577716068093, 16.01312585225436, 109.38577716068093, 99.44438045666442, 1.3851858113653537, 109.38577716068093, 107.85628248875608, 87.30496993130771, 109.38577716068093, 26.449374970375395, 56.630463341090376, 2.660839374126021, 100.59115089069623, 2.0713673299242448, 0.26688028824389387, 104.09843682518797, 109.38577716068093, 19.197759455489205, 16.01312585225436, 41.552223900940845, 9.952222871491253, 1.9055049931368127, 11.366012679870012, 108.68649614371944, 96.38994924781468, 106.44296694264851, 3.1636706588625314, 109.38577716068093, 87.44763113117196, 19.439696961624186, 15.937847398474167, 4.332446646832944, 48.8056159341168, 51.37942665646378, 107.34306793538696, 51.37942665646378, 3.671924874883045, 106.42357829557568, 1.426303912082, 109.38577716068093, 51.37942665646378, 2.26875145647812, 109.38577716068093, 9.952222871491253, 89.40126982187795, 56.630463341090376, 94.42633749387565, 100.59115089069623, 108.63719280304917, 14.716590941682917, 4.332446646832944, 1.413315546107559, 109.38577716068093, 4.06685326637397, 27.812492937308583, 56.630463341090376, 11.090013176125291, 32.35365970793698, 96.10632165160465, 87.44763113117196, 96.38994924781468, 109.38577716068093, 93.92060186136626, 103.18088292969541, 102.16974519255876, 102.91832955019052, 103.82273371138353, 0.2596008823218662, 58.71112343704222, 6.942520522485059, 42.14037933945084, 0.32612284527519353, 2.517579017917205, 8.45942436375074, 2.4033627199137055, 14.682314307035973, 2.2168600348786924, 109.38577716068093, 106.57432399615672, 1.426303912082, 12.586832928544483, 107.34306793538696, 41.552223900940845, 2.7971240678459495, 58.71112343704222, 61.87994341004333, 5.364014877195805, 0.6418507816881137, 29.42673265076175, 29.42673265076175, 0.7140345291460718, 8.625537428024007, 71.60136415716836, 32.62531429859034, 1.2602898938352696, 107.34306793538696, 106.42357829557568, 109.38577716068093, 32.810963604416905, 16.01312585225436, 10.252042766663124, 21.55929042604287, 58.71112343704222, 0.2716545906533561, 0.7999963977786411, 2.116873519739171, 70.31805732651935, 54.36004390304879, 0.7140345291460718, 0.5653455022962395, 109.38577716068093, 95.20717874257578, 4.8394088776335895, 107.34306793538696, 14.716590941682917, 107.34306793538696, 86.05719599185211, 53.162323768804136, 109.38577716068093, 9.461488857322204, 102.16974519255876, 6.128800733507789, 86.05719599185211, 1.426303912082, 13.966644159033057, 27.11786856297197, 7.284790563269179, 5.364014877195805, 15.87117921987176, 58.71112343704222, 1.383384106232056, 70.31805732651935, 103.82273371138353, 0.2596008823218662, 41.34515814495717, 75.19172487578095, 71.60136415716836, 1.9055049931368127, 41.354617433402574, 86.05719599185211, 107.85628248875608, 3.6358845410386653, 3.6358845410386653, 75.19172487578095, 10.842862537444471, 4.571501970156574, 1.9499797466347983, 104.09843682518797, 89.40126982187795, 2.0713673299242448, 95.20717874257578, 1.9055049931368127, 0.3158969107294314, 0.9182585182308902, 2.4033627199137055, 107.42158762541912, 99.44438045666442, 109.38577716068093, 84.70461501830042, 9.952222871491253, 1.9499797466347983, 109.38577716068093, 1.383384106232056, 1.383384106232056, 9.389768475957432, 6.16293010411464, 31.2252156744562, 87.44763113117196, 27.11786856297197, 42.14037933945084, 84.70461501830042, 49.85919358085994, 0.5653455022962395, 1.8984072070676443, 10.842862537444471, 108.63719280304917, 109.38577716068093, 11.366012679870012, 93.92060186136626, 5.364014877195805, 19.439696961624186, 56.630463341090376, 100.59115089069623, 61.480663666346395, 1.8984072070676443, 103.82273371138353, 19.439696961624186, 27.11786856297197, 11.090013176125291, 95.20717874257578]\n",
      "Iteration 4 , best gradient : 0.5346405312253942\n",
      "Number of new features: 288\n",
      "Number of features after pruning: 817 , 4 features pruned\n",
      "Gradient Upper bounds : [53.99534239182188, 34.476152045193075, 11.42304980255665, 49.94559606569023, 99.49696451892363, 1.2130917769320422, 0.7088346917967681, 15.308075771307683, 80.30435876530419, 1.0785151632705943, 24.421523954443266, 0.5430370958003201, 1.6481958460517192, 90.4850747299997, 1.161466221575645, 17.369829292284848, 55.658944565180846, 8.532895264655158, 17.02764589829804, 12.566748288775175, 49.94559606569023, 4.883285334227551, 49.94559606569023, 7.949202210211319, 8.026012277753363, 55.658944565180846, 91.34728489578629, 52.67933779332614, 8.940028396969174, 91.72733206266304, 72.05885970913015, 84.86055949402359, 80.82984524779798, 1.8705022322801816, 1.44863379629634, 8.026012277753363, 99.2596787450012, 0.5961238931672791, 100.69304941572209, 100.69304941572209, 1.2130917769320422, 85.50244080025723, 93.24367990730332, 18.395390369948075, 11.90315941073642, 85.50244080025723, 90.36748203822768, 100.69304941572209, 84.86055949402359, 0.5961238931672791, 3.722859582815519, 48.158946789020064, 91.34728489578629, 9.975646082989845, 100.69304941572209, 1.12270936355794, 93.24367990730332, 53.99534239182188, 17.369829292284848, 43.803636654821666, 6.253284611620321, 99.2596787450012, 30.690291769635085, 2.529870208532456, 5.7461064646333595, 1.4033152796169184, 36.38666511684724, 11.42750426452457, 53.99534239182188, 68.90590645154484, 0.6763200417910118, 74.72859069126727, 1.44863379629634, 93.24367990730332, 84.86055949402359, 91.34728489578629, 15.308075771307683, 99.61468410291612, 100.69304941572209, 6.345398393325331, 72.46927813020754, 93.34958804766596, 18.750752357844412, 39.625833224397745, 86.84077901631551, 8.532895264655158, 0.613138507741211, 10.630509528258367, 24.421523954443266, 93.08265281320418, 5.226100810454573, 43.39861813425504, 13.813219974380488, 85.71448166419249, 100.69304941572209, 8.532895264655158, 34.476152045193075, 93.08265281320418, 100.69304941572209, 0.613138507741211, 2.2242580128331584, 93.08265281320418, 18.750752357844412, 11.42304980255665, 12.483349934721353, 90.4850747299997, 43.39861813425504, 72.05885970913015, 72.46879964409904, 34.33846976144865, 17.02764589829804, 13.869075060825427, 75.39043067037179, 26.150080229367287, 20.889047540247144, 100.69304941572209, 24.906455234354794, 30.59437696545842, 6.184323647350505, 4.01170389412394, 14.153860608525763, 43.768736767280785, 1.2130917769320422, 1.1749988234862954, 80.30435876530419, 49.94559606569023, 1.8244403492979024, 100.69304941572209, 100.69304941572209, 0.37086813501644034, 72.05885970913015, 91.34728489578629, 10.630509528258367, 13.869075060825427, 63.57397368765866, 34.476152045193075, 0.4219086755976082, 15.308075771307683, 0.7919667072510583, 5.226100810454573, 10.968234310663657, 80.82984524779798, 11.052931169530906, 29.01858320016952, 0.4211250696809838, 6.184323647350505, 12.566748288775175, 99.61468410291612, 34.33846976144865, 48.158946789020064, 75.39043067037179, 100.69304941572209, 4.932568360052003, 34.476152045193075, 9.975646082989845, 72.05885970913015, 5.7461064646333595, 84.86055949402359, 90.36748203822768, 91.34728489578629, 86.84077901631551, 36.38666511684724, 91.64217629064976, 48.158946789020064, 20.674177850608334, 34.476152045193075, 73.60843911917515, 1.6481958460517192, 30.126115015983924, 24.906455234354794, 55.658944565180846, 72.46879964409904, 93.34958804766596, 20.889047540247144, 82.41961264131433, 6.345398393325331, 100.69304941572209, 84.84279844405177, 99.2596787450012, 49.94559606569023, 80.30435876530419, 9.975646082989845, 34.476152045193075, 2.717467940694111, 1.44863379629634, 2.717467940694111, 10.968234310663657, 8.282354367290333, 84.52615050731295, 2.0427781763672375, 3.722859582815519, 0.7919667072510583, 2.0427781763672375, 0.7412788381571731, 30.690291769635085, 52.01749781422164, 91.11495609697394, 91.72733206266304, 100.69304941572209, 74.1324667981, 90.4850747299997, 74.1324667981, 0.5430370958003201, 36.38666511684724, 2.9276157037524397, 74.1324667981, 2.111267322431745, 86.84077901631551, 91.72733206266304, 99.61468410291612, 91.72733206266304, 99.49696451892363, 2.529870208532456, 80.82984524779798, 1.7180359192866157, 52.01749781422164, 48.158946789020064, 49.94559606569023, 5.4252548527880915, 11.90315941073642, 66.35358703659364, 91.34728489578629, 29.712063971606153, 29.162559302857858, 55.303460529233206, 81.03608101439117, 1.787349855067362, 36.272773433909684, 55.303460529233206, 1.637508625028894, 6.184323647350505, 1.7430736929029074, 90.36748203822768, 9.432696971215401, 4.917080034656615, 30.690291769635085, 72.87267575093176, 90.36748203822768, 3.963874609867955, 34.476152045193075, 12.566748288775175, 91.11495609697394, 80.82984524779798, 100.69304941572209, 55.658944565180846, 18.750752357844412, 100.69304941572209, 1.1749988234862954, 11.90315941073642, 0.7412788381571731, 65.29804155015981, 43.39861813425504, 73.60843911917515, 91.64217629064976, 99.49696451892363, 4.883285334227551, 12.483349934721353, 0.4211250696809838, 43.768736767280785, 66.35358703659364, 29.712063971606153, 24.421523954443266, 100.69304941572209, 4.01170389412394, 3.3846943094389537, 1.145154944989894, 29.162559302857858, 93.08265281320418, 84.52615050731295, 1.637508625028894, 93.08265281320418, 75.3417291990085, 80.82984524779798, 17.02764589829804, 84.84279844405177, 84.52615050731295, 34.33846976144865, 84.52615050731295, 4.883285334227551, 43.768736767280785, 37.335154046448984, 19.72411486847928, 9.975646082989845, 20.674177850608334, 53.99534239182188, 99.61468410291612, 73.60843911917515, 91.11495609697394]\n",
      "Iteration 5 , best gradient : 3.8643542415156427\n",
      "Number of new features: 259\n",
      "Number of features after pruning: 1012 , 64 features pruned\n",
      "Gradient Upper bounds : [1.3524646885728449, 8.614978689418008, 2.4237953471197584, 14.756778376332097, 17.931417261984027, 101.25636155003096, 90.87239889664507, 90.97542895006617, 91.86664668294029, 52.58190519080104, 91.86664668294029, 24.066305046355005, 33.903064322326955, 95.89156961592248, 13.423622524582845, 6.215864546318573, 9.994251435064896, 12.646511636882106, 82.0819490355389, 96.08935243141607, 34.43128535886713, 93.20975171114722, 30.51198193054371, 9.343944769849587, 53.870208173274165, 53.870208173274165, 17.855494694077912, 1.3524646885728449, 101.25636155003096, 3.672526571615741, 24.731581279030905, 90.64181322009617, 94.53283005375096, 38.45875692422579, 2.146693652330473, 4.521218580185143, 33.08942761007646, 95.86334595007231, 0.4867299921599953, 6.833703921892178, 0.269668566993872, 103.62264619466961, 1.2190774519514946, 21.34331436675531, 17.904060727226238, 17.904060727226238, 27.635774725215946, 2.6185453419518856, 97.10077110189587, 27.700008621507315, 89.29977842761431, 6.570890676502769, 1.4499907539544286, 13.047131013194996, 1.2190774519514946, 104.29602142122792, 12.965931722302537, 15.520639922298423, 6.35556170785837, 1.0252742208726344, 0.9824260008731778, 0.5759661370487602, 89.29977842761431, 0.7812516247399977, 0.357673348243075, 0.7554194445983806, 1.7611935274029427, 1.70337624525211, 24.066305046355005, 13.019647915029326, 77.21553546817759, 53.870208173274165, 30.51198193054371, 7.979584472441262, 89.31844551990471, 94.53283005375096, 90.09969714464472, 82.0819490355389, 5.229833472677674, 101.25636155003096, 84.4045382735634, 1.0556103284839367, 2.728282195641931, 1.0250880115922527, 89.31844551990471, 7.979584472441262, 17.931417261984027, 18.667790722335397, 0.7554194445983806, 1.3763501248066305, 97.10077110189587, 94.53283005375096, 1.3763501248066305, 102.37358654809856, 95.13487769427894, 1.7851100903417534, 0.8932230832967556, 104.29602142122792, 21.34331436675531, 58.420624089913645, 0.2428919101925121, 5.7107757175369604, 7.162389702236905, 17.855494694077912, 2.1118247853826055, 83.02818814875681, 65.66945936481895, 98.39804842753819, 103.62264619466961, 101.25636155003096, 11.49063842218006, 104.29602142122792, 17.904060727226238, 3.269185326245942, 0.2428919101925121, 65.66945936481895, 7.398252338177738, 83.02818814875681, 0.9824260008731778, 93.20975171114722, 102.37358654809856, 0.6247526526301028, 89.29977842761431, 39.608387901143765, 3.1557502930453905, 90.87239889664507, 32.22988858849676, 93.20975171114722, 2.4738841200306836, 103.62264619466961, 17.931417261984027, 104.29602142122792, 0.5956608983668634, 2.1118247853826055, 90.87239889664507, 21.34331436675531, 94.53283005375096, 65.66945936481895, 104.29602142122792, 104.29602142122792, 30.51198193054371, 21.696060387758767, 104.29602142122792, 4.192013926212734, 98.39804842753819, 11.49063842218006, 10.341458632420517, 90.87239889664507, 97.10077110189587, 95.13487769427894, 102.37358654809856, 95.13487769427894, 101.25636155003096, 0.7554194445983806, 101.25636155003096, 84.4045382735634, 2.225720452882627, 5.7107757175369604, 4.785443994775924, 90.87239889664507, 104.29602142122792, 0.357673348243075, 83.02818814875681, 96.08935243141607, 1.133971214822442, 49.51395606545879, 9.994251435064896, 78.17374528943144, 90.65051267841041, 14.756778376332097, 0.6733752265582937, 9.994251435064896, 0.6247526526301028, 10.341458632420517, 101.9873254251058, 38.45875692422579, 13.047131013194996, 23.38132829555539, 90.09969714464472, 98.39804842753819, 27.700008621507315, 1.7611935274029427, 104.29602142122792, 95.89156961592248, 34.43128535886713, 52.908529964242746, 34.43128535886713, 6.570890676502769, 2.4738841200306836, 0.7812516247399977, 55.88625433008196, 5.131658738947593, 1.7584259852496138, 17.855494694077912, 13.423622524582845, 23.38132829555539, 38.45875692422579, 6.35556170785837, 4.413638803344828, 3.672526571615741, 4.413638803344828, 95.86334595007231, 0.7029748982483368, 13.423622524582845, 89.31844551990471, 90.87239889664507, 33.903064322326955, 24.731581279030905, 90.87239889664507, 0.2428919101925121, 78.17374528943144, 5.131658738947593, 0.7296219023525073, 0.24336499607999765, 13.423622524582845, 2.809058562279149, 4.785443994775924, 9.343944769849587, 2.4237953471197584, 12.292556495744243, 101.9873254251058, 53.870208173274165, 3.269185326245942, 104.29602142122792, 27.700008621507315, 91.86664668294029, 82.0819490355389, 7.979584472441262, 23.14197630286851, 5.229833472677674, 17.931417261984027, 6.215864546318573, 78.17374528943144, 10.341458632420517, 102.37358654809856, 2.728282195641931, 7.979584472441262, 0.5759661370487602, 90.64181322009617, 3.376297109020788, 0.2428919101925121, 0.7296219023525073, 95.13487769427894, 0.6733752265582937, 5.131658738947593, 0.357673348243075, 91.86664668294029, 18.667790722335397, 104.29602142122792, 17.391500250039854, 4.521218580185143, 39.608387901143765, 24.731581279030905, 23.38132829555539, 1.0252742208726344, 2.6185453419518856, 102.37358654809856, 65.66945936481895, 95.86334595007231]\n",
      "Iteration 6 , best gradient : 0.46835795664832497\n",
      "Number of new features: 169\n",
      "Number of features after pruning: 1176 , 5 features pruned\n",
      "Gradient Upper bounds : [72.61441185461243, 46.359512594751955, 40.277777816223825, 29.075605541793276, 31.29950414415747, 7.835395611379031, 12.816670435722191, 82.4605924068274, 88.2108846172636, 29.9032901641435, 6.1497767035922095, 31.29950414415747, 8.675739069424987, 0.31440977151158434, 35.94593709374909, 81.29120543490173, 10.244758422890651, 7.0935182493005335, 89.55802059079369, 3.9033116394554597, 68.37656693073504, 19.934277669992863, 81.87409985995899, 14.917301668230337, 88.2108846172636, 23.40632078013182, 8.16955354095155, 7.696406188534587, 40.277777816223825, 96.615956669062, 8.675739069424987, 87.11555160456216, 23.016318401372427, 23.40632078013182, 0.4878773532980691, 23.016318401372427, 3.525319553356278, 6.1497767035922095, 5.849695371113008, 74.0419428449742, 81.29120543490173, 4.3601341006061, 34.48653105858884, 67.32654444884776, 88.42583983147789, 10.244758422890651, 11.599717827990046, 0.9859621017794157, 0.4878773532980691, 22.74103526342043, 23.40632078013182, 81.87409985995899, 77.21566721982796, 85.9797567203518, 0.34489192151898107, 30.442510438584684, 83.49271353644556, 0.9557412295807699, 77.21566721982796, 46.359512594751955, 3.525319553356278, 46.359512594751955, 96.615956669062, 12.816670435722191, 70.4436247351519, 80.14935255250268, 10.244758422890651, 18.57700356659778, 96.615956669062, 12.816670435722191, 96.615956669062, 17.091648427011332, 67.32654444884776, 11.908057330202862, 17.091648427011332, 76.78639465779997, 30.442510438584684, 85.9797567203518, 7.0935182493005335, 23.24409555341113, 23.596234787101906, 3.1878183845923425, 88.42583983147789, 42.47480910372656, 7.0935182493005335, 29.075605541793276, 71.40694572743966, 3.1878183845923425, 8.16955354095155, 76.94068386066985, 0.6288195430231687, 4.293634193186775, 1.241516180756893, 18.57700356659778, 0.32039359519241384, 89.55802059079369, 82.68821168476065, 5.849695371113008, 2.873929565330048, 22.74103526342043, 70.4436247351519, 23.016318401372427, 71.40694572743966, 8.675739069424987, 83.65691877832064, 49.488669310663894, 89.55802059079369, 2.270892582545894, 1.4791529425215995, 83.65691877832064, 5.194035474011439, 78.25164619040896, 1.4791529425215995, 66.4307467039901, 4.3601341006061, 34.48653105858884, 9.146388579956788, 76.78639465779997, 6.933372851086926, 96.615956669062, 4.391188992753529, 81.87409985995899, 49.488669310663894, 76.78639465779997, 83.65691877832064, 63.630351351743634, 0.5820068590015068, 7.222073210850099, 77.96990065444777, 82.4605924068274, 81.87409985995899, 35.94593709374909, 29.075605541793276, 12.286385480416069, 87.11555160456216, 81.29120543490173, 0.32039359519241384, 1.241516180756893, 2.097290570695146, 22.74103526342043, 70.4436247351519, 40.277777816223825, 12.286385480416069, 49.488669310663894, 74.0419428449742, 15.162802701161942, 35.94593709374909, 74.0419428449742, 4.391188992753529, 85.9797567203518, 22.74103526342043, 80.14935255250268, 22.086861566743966, 9.146388579956788, 76.94068386066985, 7.835395611379031, 96.615956669062, 29.075605541793276, 67.32654444884776, 83.49271353644556, 49.488669310663894, 88.2108846172636, 0.4518983827170842, 46.359512594751955, 30.442510438584684, 12.286385480416069, 10.671977847539576, 82.68821168476065, 88.42583983147789]\n",
      "Iteration 7 , best gradient : 3.5143089384773387\n",
      "Number of new features: 89\n",
      "Number of features after pruning: 1244 , 21 features pruned\n",
      "Gradient Upper bounds : [86.20999282229666, 32.927391394557944, 86.37098585005288, 1.0083795109585054, 8.54498522786251, 15.930415684520211, 100.67733942046756, 0.1984586525191569, 87.18978091647426, 0.6631271297451108, 27.60889988998646, 78.17715395500768, 1.0083795109585054, 16.913564995959025, 3.9851352776790767, 10.132811794786793, 6.374177644096948, 10.132811794786793, 53.0393870986942, 18.745464121778078, 2.2370813302310806, 91.3781889353259, 15.17202923994022, 78.17715395500768, 1.0358867947552546, 33.572247985213586, 96.28811966331905, 1.548043726288592, 16.913564995959025, 1.0358867947552546, 86.37098585005288, 0.4461135539308625, 98.84390087340576, 74.168464130251, 0.6634080674944229, 78.17715395500768, 32.927391394557944, 6.636223189711517, 49.63439161873146, 10.675182280509809, 80.52514508270049, 91.3781889353259, 96.28811966331905, 1.9111090710283556, 51.549312382520036, 98.84390087340576, 100.67733942046756, 5.907252062202932, 1.0083795109585054, 6.627044012077713, 24.172762818536057, 0.5607542328074608, 64.9533839181123, 27.320903141961725, 5.907252062202932, 45.61142666874043, 15.780715581664648, 8.54498522786251, 50.87917590658785, 0.34268305826552786, 0.5607542328074608, 0.23336694467320152, 3.8419945831411058, 6.4377645371923595, 0.23336694467320152, 27.320903141961725, 45.61142666874043, 8.374675260425148, 8.110339390563844, 18.745464121778078, 26.627841572487643, 15.780715581664648, 64.9533839181123, 0.1984586525191569, 8.374675260425148, 32.927391394557944, 6.636223189711517, 6.627044012077713, 27.60889988998646, 0.8848565237942696, 15.607619211427469, 3.8419945831411058, 2.9423183532759047, 15.17202923994022, 10.132811794786793, 6.374177644096948, 5.252499945552153, 1.880252103778798, 27.60889988998646]\n",
      "Iteration 8 , best gradient : 0.4209027355572331\n",
      "Number of new features: 18\n",
      "Number of features after pruning: 1261 , 1 features pruned\n",
      "Gradient Upper bounds : [8.004538971873663, 0.5677428357830916, 3.678949149353476, 10.509659970168599, 10.509659970168599, 8.004538971873663, 74.6907135536745, 56.12890248001412, 4.844577573467118, 14.00258563331472, 1.7120802312235317, 56.12890248001412, 74.6907135536745, 14.00258563331472, 0.3032011090764236, 8.921169088765875, 8.921169088765875, 20.14767149192571]\n",
      "Iteration 9 , best gradient : 5.8408257682289015\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 10 , best gradient : 0.3445157207652595\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 11 , best gradient : 7.126096797480658\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 12 , best gradient : 6.203448168949944\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 13 , best gradient : 5.590351377254328\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 14 , best gradient : 5.013809062147592\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 15 , best gradient : 4.583964803795288\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 16 , best gradient : 4.1735012658596915\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 17 , best gradient : 3.847964715386487\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 18 , best gradient : 3.534939937195294\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 19 , best gradient : 3.2767956926389146\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 20 , best gradient : 3.0278470636444976\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 21 , best gradient : 2.816941569944183\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 22 , best gradient : 2.61339122187891\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 23 , best gradient : 2.4375293037028127\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 24 , best gradient : 2.2678734890458063\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 25 , best gradient : 2.1191026035700324\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 26 , best gradient : 1.9757421565874782\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 27 , best gradient : 1.8485691546938574\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 28 , best gradient : 1.7262047834513619\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 29 , best gradient : 1.6166569063581193\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 30 , best gradient : 1.5114295464084848\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 31 , best gradient : 1.416523881586009\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 32 , best gradient : 1.32552223863857\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 33 , best gradient : 1.2429488319838682\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 34 , best gradient : 1.1639118124056176\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 35 , best gradient : 1.0918356234090187\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 36 , best gradient : 1.0229644633278856\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 37 , best gradient : 0.9598967803290036\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 38 , best gradient : 0.8997319370835636\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 39 , best gradient : 0.8444440746685665\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 40 , best gradient : 0.7917818913721923\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 41 , best gradient : 0.7432455176865888\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 42 , best gradient : 0.6970801431771636\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 43 , best gradient : 0.6544248758963455\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 44 , best gradient : 0.6139066915281882\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 45 , best gradient : 0.5763891836428914\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 46 , best gradient : 0.5407942992494112\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 47 , best gradient : 0.507775150368719\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 48 , best gradient : 0.47648249881557325\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 49 , best gradient : 0.4474086143388498\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 50 , best gradient : 0.4198823778453609\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 51 , best gradient : 0.3942732016799944\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 52 , best gradient : 0.37004905858529324\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 53 , best gradient : 0.3474856177448668\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 54 , best gradient : 0.3261597829941454\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 55 , best gradient : 0.3062758157588033\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 56 , best gradient : 0.28749616516720716\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 57 , best gradient : 0.27504347834092424\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 58 , best gradient : 0.7740004312420342\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 59 , best gradient : 0.7255401858661754\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 60 , best gradient : 0.6795276001152092\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 61 , best gradient : 0.6370526645731817\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 62 , best gradient : 0.5967761120462305\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 63 , best gradient : 0.5595177817118632\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 64 , best gradient : 0.5242302717897847\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 65 , best gradient : 0.4915283412964411\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 66 , best gradient : 0.4605900064222846\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 67 , best gradient : 0.4318743500091201\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 68 , best gradient : 0.40473411252889496\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 69 , best gradient : 0.3795102948477693\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 70 , best gradient : 0.35569150896169127\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 71 , best gradient : 0.3335293207660281\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 72 , best gradient : 0.31261832078826335\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 73 , best gradient : 0.2931424831671626\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 74 , best gradient : 0.2747793007279048\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 75 , best gradient : 0.2676370656059961\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 76 , best gradient : 0.7575411188710091\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 77 , best gradient : 0.709132262849927\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 78 , best gradient : 0.663246763864336\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 79 , best gradient : 0.6209289786847183\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 80 , best gradient : 0.5808697729449843\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 81 , best gradient : 0.5438483443130426\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 82 , best gradient : 0.5088447736554137\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 83 , best gradient : 0.47643825069291895\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 84 , best gradient : 0.44583127140557754\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 85 , best gradient : 0.4174522166918717\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 86 , best gradient : 0.3906752584536985\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 87 , best gradient : 0.3658151968544822\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 88 , best gradient : 0.3423791625785943\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 89 , best gradient : 0.32059657648850465\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 90 , best gradient : 0.30007786936343595\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 91 , best gradient : 0.2809884541167477\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 92 , best gradient : 0.26301926515864205\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 93 , best gradient : 0.26072835850542514\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 94 , best gradient : 0.7420782375862736\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 95 , best gradient : 0.6937109180603842\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 96 , best gradient : 0.6479412846074549\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 97 , best gradient : 0.6057705544365002\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 98 , best gradient : 0.5659171334837148\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 99 , best gradient : 0.5291218901907978\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 100 , best gradient : 0.4943900594105229\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 101 , best gradient : 0.4622673918599897\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 102 , best gradient : 0.4319787782044762\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 103 , best gradient : 0.40392384481413385\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 104 , best gradient : 0.3774963371154841\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 105 , best gradient : 0.3529866199294698\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 106 , best gradient : 0.3299186967231224\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 107 , best gradient : 0.308501430168377\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 108 , best gradient : 0.28835964212580834\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 109 , best gradient : 0.27083047370877705\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 110 , best gradient : 0.7563104577983554\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 111 , best gradient : 0.7059760550121792\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 112 , best gradient : 0.6584088216740578\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 113 , best gradient : 0.6146553923136453\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 114 , best gradient : 0.5733631314919173\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 115 , best gradient : 0.5353005478283909\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 116 , best gradient : 0.49942299197196766\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 117 , best gradient : 0.46629194128557966\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 118 , best gradient : 0.43509729074278014\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 119 , best gradient : 0.40624654108197156\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 120 , best gradient : 0.37910892631430654\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 121 , best gradient : 0.3539776338179463\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 122 , best gradient : 0.3303595368112555\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 123 , best gradient : 0.3084631853077293\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 124 , best gradient : 0.2879014624981018\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 125 , best gradient : 0.26907120962115566\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 126 , best gradient : 0.749773892625527\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 127 , best gradient : 0.6988565606682063\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 128 , best gradient : 0.6508168671739172\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 129 , best gradient : 0.6066831931835249\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 130 , best gradient : 0.5651003868640548\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 131 , best gradient : 0.5268169333832059\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 132 , best gradient : 0.4907905994108683\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 133 , best gradient : 0.4575629693343946\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 134 , best gradient : 0.4263289834068559\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 135 , best gradient : 0.3974774697843876\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 136 , best gradient : 0.37038389208357503\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 137 , best gradient : 0.3453245482805308\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 138 , best gradient : 0.3218128446910028\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 139 , best gradient : 0.3000424516877186\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 140 , best gradient : 0.2796325763665909\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 141 , best gradient : 0.2637648835951567\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 142 , best gradient : 0.7371209305822479\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 143 , best gradient : 0.6860757056750146\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 144 , best gradient : 0.6379971414973338\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 145 , best gradient : 0.5938758904071408\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 146 , best gradient : 0.5523754706657718\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 147 , best gradient : 0.5142101849942865\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 148 , best gradient : 0.4783560543421844\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 149 , best gradient : 0.4453245468594343\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 150 , best gradient : 0.41432750580731775\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 151 , best gradient : 0.38572777174047035\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 152 , best gradient : 0.35891592665948807\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 153 , best gradient : 0.3341462058536928\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 154 , best gradient : 0.31094522009840736\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 155 , best gradient : 0.28948815653420923\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 156 , best gradient : 0.2694055600772539\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 157 , best gradient : 0.25761013266826077\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 158 , best gradient : 0.7230939032402142\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 159 , best gradient : 0.6720649636212706\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 160 , best gradient : 0.6240833098198274\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 161 , best gradient : 0.5800972109358933\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 162 , best gradient : 0.5387940920633031\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 163 , best gradient : 0.500851041382558\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 164 , best gradient : 0.4652659902574624\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 165 , best gradient : 0.43251841483363007\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 166 , best gradient : 0.40183958208146014\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 167 , best gradient : 0.3735652812878658\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 168 , best gradient : 0.3471029233315005\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 169 , best gradient : 0.32268417631291296\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 170 , best gradient : 0.2998499928178985\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 171 , best gradient : 0.27875694698741404\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 172 , best gradient : 0.25904765782425265\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 173 , best gradient : 0.2514456624802478\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 174 , best gradient : 0.7091591269069811\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 175 , best gradient : 0.6581896347117084\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 176 , best gradient : 0.6103441566102458\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 177 , best gradient : 0.566528514797704\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 178 , best gradient : 0.5254542884300669\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 179 , best gradient : 0.4877617167401002\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 180 , best gradient : 0.4524705286496553\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 181 , best gradient : 0.4200288397208805\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 182 , best gradient : 0.38968700673010775\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 183 , best gradient : 0.361754545880606\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 184 , best gradient : 0.3356552406444236\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 185 , best gradient : 0.3115990323104634\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 186 , best gradient : 0.28914070480160897\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 187 , best gradient : 0.2684190637333164\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 188 , best gradient : 0.24908828304814074\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 189 , best gradient : 0.24551171121841622\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 190 , best gradient : 0.6957310276297463\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 191 , best gradient : 0.6448323611587128\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 192 , best gradient : 0.5971320873975507\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 193 , best gradient : 0.5534948118528131\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 194 , best gradient : 0.5126550865906329\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 195 , best gradient : 0.4752175950745341\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 196 , best gradient : 0.4402226975040368\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 197 , best gradient : 0.4080884377799968\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 198 , best gradient : 0.37808315261915426\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 199 , best gradient : 0.3504913221072933\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 200 , best gradient : 0.3247520756591428\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 201 , best gradient : 0.3010547813611356\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 202 , best gradient : 0.2789671259544775\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 203 , best gradient : 0.2586111983633609\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 204 , best gradient : 0.2444600780833959\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 205 , best gradient : 3.585560339972372\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 206 , best gradient : 2.7961585128573065\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 207 , best gradient : 2.228577188475282\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 208 , best gradient : 1.7596948207827217\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 209 , best gradient : 1.4057953535150856\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 210 , best gradient : 1.1159266337246143\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 211 , best gradient : 0.8918530561464443\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 212 , best gradient : 0.7097362211262683\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 213 , best gradient : 0.5671225780211713\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 214 , best gradient : 0.4518933193833329\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 215 , best gradient : 0.36098575476839206\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 216 , best gradient : 0.28783860212191953\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 217 , best gradient : 0.22987502087282485\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 218 , best gradient : 0.18336675619896123\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 219 , best gradient : 0.18737577632267485\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 220 , best gradient : 0.5130852414923669\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 221 , best gradient : 0.4093311815217532\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 222 , best gradient : 0.3258814493842113\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 223 , best gradient : 0.2599115447955249\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 224 , best gradient : 0.20701889492139547\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 225 , best gradient : 0.1956283176364325\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 226 , best gradient : 0.5230245350974023\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 227 , best gradient : 0.4166566944000691\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 228 , best gradient : 0.33121871687854887\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 229 , best gradient : 0.2637846004954854\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 230 , best gradient : 0.20979325179465405\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 231 , best gradient : 0.1956852107609922\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 232 , best gradient : 0.5208187679815308\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 233 , best gradient : 0.41428884702058766\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 234 , best gradient : 0.32885247868211814\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 235 , best gradient : 0.26151388168872064\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 236 , best gradient : 0.20768172070125937\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 237 , best gradient : 0.19384086817728505\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 238 , best gradient : 0.5158318804156128\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 239 , best gradient : 0.40971870045242315\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 240 , best gradient : 0.3247509731530688\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 241 , best gradient : 0.25787195668852647\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 242 , best gradient : 0.2044905001089265\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 243 , best gradient : 0.19159114291388993\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 244 , best gradient : 0.5102848609464902\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 245 , best gradient : 0.4047199595675857\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 246 , best gradient : 0.32032473478309814\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 247 , best gradient : 0.2539847260557657\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 248 , best gradient : 0.20111580350294983\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 249 , best gradient : 0.18928733896073985\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 250 , best gradient : 0.5046976564372305\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 251 , best gradient : 0.399706776473467\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 252 , best gradient : 0.3159022054312926\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 253 , best gradient : 0.2501135724086397\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 254 , best gradient : 0.19776503329578426\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 255 , best gradient : 0.1870102466407976\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 256 , best gradient : 0.4991888182466425\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 257 , best gradient : 0.3947729899720581\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 258 , best gradient : 0.31155728424875206\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 259 , best gradient : 0.24631684001818266\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 260 , best gradient : 0.19448407791098898\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 261 , best gradient : 0.18477733565271767\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 262 , best gradient : 0.4937831131443538\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 263 , best gradient : 0.3899377293956416\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 264 , best gradient : 0.30730460580892954\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 265 , best gradient : 0.24260568781164066\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 266 , best gradient : 0.19128136119304895\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 267 , best gradient : 0.182591424048063\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 268 , best gradient : 0.4884836690991501\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 269 , best gradient : 0.3852029293611472\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 270 , best gradient : 0.30314520072453977\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 271 , best gradient : 0.23898047518215387\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 272 , best gradient : 0.18815675912250604\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 273 , best gradient : 0.18045200543491965\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 274 , best gradient : 0.48328873992116883\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 275 , best gradient : 0.3805666736303269\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 276 , best gradient : 0.29907707285705903\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 277 , best gradient : 0.23543917719335739\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 278 , best gradient : 0.18510827695083157\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 279 , best gradient : 0.1783578599879541\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 280 , best gradient : 0.47819556266090885\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 281 , best gradient : 0.3760262600807827\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 282 , best gradient : 0.2950976245475116\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 283 , best gradient : 0.23197931048893883\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 284 , best gradient : 0.18213357442462708\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 285 , best gradient : 0.17755055254561478\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 286 , best gradient : 4.093193064527698\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 287 , best gradient : 2.7516972493018312\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 288 , best gradient : 1.819629867860648\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 289 , best gradient : 1.2285738573598337\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 290 , best gradient : 0.8220683684422124\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 291 , best gradient : 0.5545013707129822\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 292 , best gradient : 0.37236074200931607\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 293 , best gradient : 0.2509018295705112\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 294 , best gradient : 0.168706406478568\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 295 , best gradient : 0.1457475875566301\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 296 , best gradient : 0.3638271139348517\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 297 , best gradient : 0.24481583312028393\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 298 , best gradient : 0.1643961109862285\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 299 , best gradient : 0.14364507530569973\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 300 , best gradient : 0.35974982221100454\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 301 , best gradient : 0.24174718919522886\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 302 , best gradient : 0.1621209508659907\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 303 , best gradient : 0.1422264512392721\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 304 , best gradient : 0.3565418976258385\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 305 , best gradient : 0.23927248334381088\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 306 , best gradient : 0.16025036616031724\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 307 , best gradient : 0.14095042510082575\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 308 , best gradient : 0.35353003269925243\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 309 , best gradient : 0.2369373059370308\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 310 , best gradient : 0.15847889836306678\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 311 , best gradient : 0.13971560091982882\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 312 , best gradient : 0.35058797558374283\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 313 , best gradient : 0.23465641882841717\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 314 , best gradient : 0.156749207448179\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 315 , best gradient : 0.13919256261985627\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 316 , best gradient : 3.0451880221745093\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 317 , best gradient : 1.7650007468762494\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 318 , best gradient : 1.0071685316902657\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 319 , best gradient : 0.5828567665888131\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 320 , best gradient : 0.335209235819108\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 321 , best gradient : 0.19358818222610624\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 322 , best gradient : 0.11155385819108904\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 323 , best gradient : 0.11222554621468293\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 324 , best gradient : 2.365391831817338\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 325 , best gradient : 1.196072474579386\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 326 , best gradient : 0.5962729647699551\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 327 , best gradient : 0.30020237269237204\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 328 , best gradient : 0.15050854870607347\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 329 , best gradient : 0.1058109534987625\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 330 , best gradient : 0.2357376583842252\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 331 , best gradient : 0.12635234622954825\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 332 , best gradient : 0.25326922706234667\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 333 , best gradient : 0.13011967722048878\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 334 , best gradient : 0.2555346748244466\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 335 , best gradient : 0.1301120145379142\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 336 , best gradient : 0.25438140757964467\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 337 , best gradient : 0.1292657976925334\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 338 , best gradient : 0.2524813455539536\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 339 , best gradient : 0.12824231778422956\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 340 , best gradient : 0.2504350425170388\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 341 , best gradient : 0.12718988300818138\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 342 , best gradient : 0.24837676741031883\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 343 , best gradient : 0.12614149993052318\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 344 , best gradient : 0.24633615624455296\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 345 , best gradient : 0.12510434434928322\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 346 , best gradient : 0.2443194462888854\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 347 , best gradient : 0.12407982687906716\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 348 , best gradient : 0.2423276651705444\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 349 , best gradient : 0.1230680787367895\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 350 , best gradient : 0.24036069057634746\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 351 , best gradient : 0.12206895132340578\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 352 , best gradient : 0.23841815334138555\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 353 , best gradient : 0.121082238179857\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 354 , best gradient : 0.23649963754877848\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 355 , best gradient : 0.12010772403360256\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 356 , best gradient : 0.23460472456546752\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 357 , best gradient : 0.11914519552016473\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 358 , best gradient : 0.23273300254432205\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 359 , best gradient : 0.11819444343885886\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 360 , best gradient : 0.23088406831311523\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 361 , best gradient : 0.11725526314668841\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 362 , best gradient : 0.22905752759505865\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 363 , best gradient : 0.11632745454646236\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 364 , best gradient : 0.22725299486933778\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 365 , best gradient : 0.1154108219890462\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 366 , best gradient : 0.22547009315873143\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 367 , best gradient : 0.11450517415979611\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 368 , best gradient : 0.2237084538068959\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 369 , best gradient : 0.11361032396437853\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 370 , best gradient : 0.2219677162587297\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 371 , best gradient : 0.1127260884171524\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 372 , best gradient : 0.22024752784665372\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 373 , best gradient : 0.11185228853276899\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 374 , best gradient : 0.218547543583167\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 375 , best gradient : 0.11098874922100041\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 376 , best gradient : 0.21686742595961986\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 377 , best gradient : 0.11013529918473466\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 378 , best gradient : 0.21520684475104324\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 379 , best gradient : 0.10929177082103297\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 380 , best gradient : 0.21356547682681953\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 381 , best gradient : 0.10845800012516095\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 382 , best gradient : 0.21194300596700458\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 383 , best gradient : 0.10763382659746207\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 384 , best gradient : 0.21033912268411084\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 385 , best gradient : 0.1068190931530397\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 386 , best gradient : 0.20875352405018674\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 387 , best gradient : 0.10601364603407266\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 388 , best gradient : 0.20718591352902585\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 389 , best gradient : 0.10521733472477318\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 390 , best gradient : 0.20563600081326247\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 391 , best gradient : 0.10443001186880499\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 392 , best gradient : 0.20410350166633798\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 393 , best gradient : 0.10365153318915381\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 394 , best gradient : 0.202588137769005\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 395 , best gradient : 0.10288175741033324\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 396 , best gradient : 0.20108963657037326\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 397 , best gradient : 0.1021205461828618\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 398 , best gradient : 0.19960773114324773\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 399 , best gradient : 0.10136776400992918\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 400 , best gradient : 0.19814216004367133\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 401 , best gradient : 0.10062327817619503\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 402 , best gradient : 0.1966926671745327\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 403 , best gradient : 0.09988695867862933\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 404 , best gradient : 0.19525900165305823\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 405 , best gradient : 0.09915867815935783\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 406 , best gradient : 0.19384091768215342\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 407 , best gradient : 0.09843831184041629\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 408 , best gradient : 0.1924381744253925\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 409 , best gradient : 0.09772573746038363\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 410 , best gradient : 0.1910505358855483\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 411 , best gradient : 0.09702083521279209\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 412 , best gradient : 0.18967777078661552\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 413 , best gradient : 0.09632348768632638\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 414 , best gradient : 0.18831965245912607\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 415 , best gradient : 0.09563357980666425\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 416 , best gradient : 0.18697595872870576\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 417 , best gradient : 0.09495099877998843\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 418 , best gradient : 0.18564647180778315\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 419 , best gradient : 0.09427563403806755\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 420 , best gradient : 0.18433097819027733\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 421 , best gradient : 0.09360737718488298\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 422 , best gradient : 0.18302926854928156\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 423 , best gradient : 0.09294612194473108\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 424 , best gradient : 0.1817411376375454\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 425 , best gradient : 0.09244374104118236\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 426 , best gradient : 1.0177334331828547\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 427 , best gradient : 0.4429485845883504\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 428 , best gradient : 0.19121665701207563\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 429 , best gradient : 0.08618412620973014\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 430 , best gradient : 0.15916654273372005\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 431 , best gradient : 0.08304163532319489\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 432 , best gradient : 1.5869669133206687\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 433 , best gradient : 0.6061338206649626\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 434 , best gradient : 0.22847628211407406\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 435 , best gradient : 0.08662522927731851\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 436 , best gradient : 0.06869229290818284\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 437 , best gradient : 0.44687048523929057\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 438 , best gradient : 0.1547176622189179\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 439 , best gradient : 0.0659109977459434\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 440 , best gradient : 1.1950432802630424\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 441 , best gradient : 0.36894271023310604\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 442 , best gradient : 0.1126613928159896\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 443 , best gradient : 0.05682024897150641\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 444 , best gradient : 0.5897422399959619\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 445 , best gradient : 0.15878639095260047\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 446 , best gradient : 0.06126498286391905\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 447 , best gradient : 0.10556596670817935\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 448 , best gradient : 0.05425300783753185\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 449 , best gradient : 0.10284008363573714\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 450 , best gradient : 0.05369740495172276\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 451 , best gradient : 0.10222584955991598\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 452 , best gradient : 0.05341298213148214\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 453 , best gradient : 0.10170220646262039\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 454 , best gradient : 0.053141073686118895\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 455 , best gradient : 0.10118457464029287\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 456 , best gradient : 0.05287084610316595\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 457 , best gradient : 0.10066940338654902\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 458 , best gradient : 0.052601841623294725\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 459 , best gradient : 0.10015653684028214\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 460 , best gradient : 0.05239332421277133\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 461 , best gradient : 0.3061340402400587\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 462 , best gradient : 0.07621230685151885\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 463 , best gradient : 0.10584241980590259\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 464 , best gradient : 0.05246177838607634\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 465 , best gradient : 0.09859946281511338\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 466 , best gradient : 0.05141340368276443\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 467 , best gradient : 0.09789137743230139\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 468 , best gradient : 0.051136502470303345\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 469 , best gradient : 0.09740712480290883\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 470 , best gradient : 0.050886842064643015\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 471 , best gradient : 0.09693245854124745\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 472 , best gradient : 0.05063914003585375\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 473 , best gradient : 0.09646008975442408\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 474 , best gradient : 0.050392533296979694\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 475 , best gradient : 0.09598976415898357\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 476 , best gradient : 0.0501469892080586\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 477 , best gradient : 0.09552146688269769\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 478 , best gradient : 0.04990250340609874\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 479 , best gradient : 0.09505519121077276\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 480 , best gradient : 0.049659072492128385\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 481 , best gradient : 0.09459093070622031\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 482 , best gradient : 0.049416693100183234\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 483 , best gradient : 0.09412867894128704\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 484 , best gradient : 0.049175361865659385\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 485 , best gradient : 0.09366842948853317\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 486 , best gradient : 0.04893507542435468\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 487 , best gradient : 0.09321017592077122\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 488 , best gradient : 0.04869583041255224\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 489 , best gradient : 0.09275391181130821\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 490 , best gradient : 0.04845762346714907\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 491 , best gradient : 0.09229963073419443\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 492 , best gradient : 0.04831958823891963\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 493 , best gradient : 0.5084171235257758\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 494 , best gradient : 0.11730518448657223\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 495 , best gradient : 0.05180350229646048\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 496 , best gradient : 0.0945384043913431\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 497 , best gradient : 0.0491264987822259\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 498 , best gradient : 0.09347116609450223\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 499 , best gradient : 0.04882561526519469\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 500 , best gradient : 0.09300971579915568\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 501 , best gradient : 0.048591867667124894\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 502 , best gradient : 0.09256695636933895\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 503 , best gradient : 0.048360932598181285\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 504 , best gradient : 0.09212651485683004\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 505 , best gradient : 0.04813101296688537\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 506 , best gradient : 0.09168792871867641\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 507 , best gradient : 0.047902055726928114\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 508 , best gradient : 0.09125117957764915\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 509 , best gradient : 0.047674056546476495\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 510 , best gradient : 0.0908162614732384\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 511 , best gradient : 0.04744701245649424\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 512 , best gradient : 0.09038316879257273\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 513 , best gradient : 0.04722092052642004\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 514 , best gradient : 0.08995189593273939\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 515 , best gradient : 0.04699577782717615\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 516 , best gradient : 0.08952243729150021\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 517 , best gradient : 0.046771581430205815\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 518 , best gradient : 0.08909478726720128\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 519 , best gradient : 0.04654832840754262\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 520 , best gradient : 0.08866894025894112\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 521 , best gradient : 0.04632601583187974\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 522 , best gradient : 0.08824489066674493\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 523 , best gradient : 0.04610464077667753\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 524 , best gradient : 0.08782263289173749\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 525 , best gradient : 0.04588420031622506\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 526 , best gradient : 0.08740216133630342\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 527 , best gradient : 0.04566469152573826\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 528 , best gradient : 0.08698347040426618\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 529 , best gradient : 0.04544611148143411\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 530 , best gradient : 0.08656655450104302\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 531 , best gradient : 0.04526780224413167\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 532 , best gradient : 0.2597637551123397\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 533 , best gradient : 0.06272096100595932\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 534 , best gradient : 0.08997037282787795\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 535 , best gradient : 0.04534593789142508\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 536 , best gradient : 0.08573729242649895\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 537 , best gradient : 0.044749132477925196\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 538 , best gradient : 0.08525554625332096\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 539 , best gradient : 0.04453432425147035\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 540 , best gradient : 0.08486063001273393\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 541 , best gradient : 0.044329024824522306\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 542 , best gradient : 0.08446926211386302\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 543 , best gradient : 0.04412476186366706\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 544 , best gradient : 0.08407954239411404\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 545 , best gradient : 0.043921339911563315\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 546 , best gradient : 0.08369142267822446\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 547 , best gradient : 0.04371875196612045\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 548 , best gradient : 0.08330489699754914\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 549 , best gradient : 0.04351699532400147\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 550 , best gradient : 0.08291996035014366\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 551 , best gradient : 0.04331606738209199\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 552 , best gradient : 0.08253660775985072\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 553 , best gradient : 0.043115965541680866\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 554 , best gradient : 0.08215483425488274\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 555 , best gradient : 0.042916687206329435\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 556 , best gradient : 0.08177463486743779\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 557 , best gradient : 0.04271822978186641\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 558 , best gradient : 0.0813960046337915\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 559 , best gradient : 0.04252059067642638\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 560 , best gradient : 0.0810189385943876\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 561 , best gradient : 0.04232376730051219\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 562 , best gradient : 0.08064343179393177\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 563 , best gradient : 0.04212775706702793\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 564 , best gradient : 0.08026947928149786\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 565 , best gradient : 0.04193255739133008\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 566 , best gradient : 0.07989707611060755\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 567 , best gradient : 0.04173816569127411\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 568 , best gradient : 0.07952621733933365\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 569 , best gradient : 0.04154457938725274\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 570 , best gradient : 0.07915689803038414\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 571 , best gradient : 0.04135179590225169\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 572 , best gradient : 0.07878911325120093\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 573 , best gradient : 0.04129511822507485\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 574 , best gradient : 0.23378913315439223\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 575 , best gradient : 0.055825526117904256\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 576 , best gradient : 0.08140926350743821\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 577 , best gradient : 0.041295619371823834\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 578 , best gradient : 0.07824502246038065\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 579 , best gradient : 0.04084578899429395\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 580 , best gradient : 0.07784228981191153\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 581 , best gradient : 0.04065789505297661\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 582 , best gradient : 0.07749218964244035\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 583 , best gradient : 0.040475586018756296\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 584 , best gradient : 0.07714444617828885\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 585 , best gradient : 0.04029409965666014\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 586 , best gradient : 0.07679812075558164\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 587 , best gradient : 0.0401133451561578\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 588 , best gradient : 0.0764531915715812\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 589 , best gradient : 0.039933318564013165\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 590 , best gradient : 0.07610965389035791\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 591 , best gradient : 0.03975401754695543\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 592 , best gradient : 0.07576750329928654\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 593 , best gradient : 0.03957543980479682\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 594 , best gradient : 0.07542673539711636\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 595 , best gradient : 0.03939758304089089\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 596 , best gradient : 0.07508734578820433\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 597 , best gradient : 0.03922044496159369\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 598 , best gradient : 0.0747493300824645\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 599 , best gradient : 0.039075065240942355\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 600 , best gradient : 0.6803471758070042\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 601 , best gradient : 0.1217020080449291\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 602 , best gradient : 0.04273593456159957\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 603 , best gradient : 0.07444943298652938\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 604 , best gradient : 0.03860799162621233\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 605 , best gradient : 0.07351323367142931\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 606 , best gradient : 0.03839003368941769\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 607 , best gradient : 0.07318884608138519\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 608 , best gradient : 0.0382243244968207\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 609 , best gradient : 0.07287375190578593\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 610 , best gradient : 0.038059937013642325\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 611 , best gradient : 0.07255998740101054\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 612 , best gradient : 0.03789619612748205\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 613 , best gradient : 0.07224744345268438\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 614 , best gradient : 0.037733090946939496\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 615 , best gradient : 0.07193611487375647\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 616 , best gradient : 0.037570619376145545\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 617 , best gradient : 0.07162599785992428\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 618 , best gradient : 0.037408779438908225\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 619 , best gradient : 0.07131708863095164\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 620 , best gradient : 0.03724756916369673\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 621 , best gradient : 0.07100938341267858\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 622 , best gradient : 0.0370869865821359\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 623 , best gradient : 0.07070287843678645\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 624 , best gradient : 0.03692702972899497\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 625 , best gradient : 0.07039756994084376\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 626 , best gradient : 0.03676769664219646\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 627 , best gradient : 0.0700934541683189\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 628 , best gradient : 0.0366089853628335\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 629 , best gradient : 0.06979052736860313\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 630 , best gradient : 0.03645089393517531\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 631 , best gradient : 0.06948878579704844\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 632 , best gradient : 0.03629342040668006\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 633 , best gradient : 0.06918822571497796\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 634 , best gradient : 0.036136562828009394\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 635 , best gradient : 0.06888884338971747\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 636 , best gradient : 0.03598031925303031\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 637 , best gradient : 0.06859063509462072\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 638 , best gradient : 0.035986674680865485\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 639 , best gradient : 0.19900387643006012\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 640 , best gradient : 0.046169040163870294\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 641 , best gradient : 0.06997253685865601\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 642 , best gradient : 0.036064243991055504\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 643 , best gradient : 0.5061168937680773\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 644 , best gradient : 0.08550342927381516\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 645 , best gradient : 0.03626939313239169\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 646 , best gradient : 0.25213850479803745\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 647 , best gradient : 0.04403363948884413\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 648 , best gradient : 0.05790454190763986\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 649 , best gradient : 0.0704569338496243\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 650 , best gradient : 0.03559716758759075\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 651 , best gradient : 0.06750749161411093\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 652 , best gradient : 0.03524883773451005\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 653 , best gradient : 0.06720312567119299\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 654 , best gradient : 0.03510081472844302\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 655 , best gradient : 0.06692386449649669\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 656 , best gradient : 0.035019184422950544\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 657 , best gradient : 0.3345448360214093\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 658 , best gradient : 0.049120856562168164\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 659 , best gradient : 0.03461390049771225\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 660 , best gradient : 0.06849293406459661\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 661 , best gradient : 0.03583466039564298\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 662 , best gradient : 0.06834526478811956\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 663 , best gradient : 0.035697914473249645\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 664 , best gradient : 0.06806755938973047\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 665 , best gradient : 0.03555258702306584\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 666 , best gradient : 0.06779000069118188\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 667 , best gradient : 0.035407734162677014\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 668 , best gradient : 0.06751346112616168\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 669 , best gradient : 0.035263415232924894\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 670 , best gradient : 0.06723794351665337\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 671 , best gradient : 0.0351196290404455\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 672 , best gradient : 0.06696344483024746\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 673 , best gradient : 0.034976373986542846\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 674 , best gradient : 0.06668996200025851\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 675 , best gradient : 0.034833648472594785\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 676 , best gradient : 0.06641749196503394\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 677 , best gradient : 0.03469145090277662\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 678 , best gradient : 0.06614603166821328\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 679 , best gradient : 0.03454977968408933\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 680 , best gradient : 0.0658755780587488\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 681 , best gradient : 0.03440863322636284\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 682 , best gradient : 0.06560612809091272\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 683 , best gradient : 0.03426800994225375\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 684 , best gradient : 0.06533767872429215\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 685 , best gradient : 0.03412790824725205\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 686 , best gradient : 0.06507022692380673\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 687 , best gradient : 0.03398832655967943\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 688 , best gradient : 0.06480376965971178\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 689 , best gradient : 0.0338492633006968\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 690 , best gradient : 0.06453830390760586\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 691 , best gradient : 0.03371071689429689\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 692 , best gradient : 0.06427382664843465\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 693 , best gradient : 0.0335726857673243\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 694 , best gradient : 0.06401033486850106\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 695 , best gradient : 0.03343516834945064\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 696 , best gradient : 0.06374782555946948\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 697 , best gradient : 0.03337471347867075\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 698 , best gradient : 0.24909543387422628\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 699 , best gradient : 0.04127238408862749\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 700 , best gradient : 0.05554130335001629\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 701 , best gradient : 0.03254342483572338\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 702 , best gradient : 0.4617120178900265\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 703 , best gradient : 0.06456314790786119\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 704 , best gradient : 0.03276090021830406\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 705 , best gradient : 0.22543691762950666\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 706 , best gradient : 0.03937505936972567\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 707 , best gradient : 0.05551259968056938\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 708 , best gradient : 0.03108026653296569\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 709 , best gradient : 0.21339036829949118\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 710 , best gradient : 0.037598678568143196\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 711 , best gradient : 0.0547092056629502\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 712 , best gradient : 0.030177086297300627\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 713 , best gradient : 0.2621097768790433\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 714 , best gradient : 0.03977280031144685\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 715 , best gradient : 0.05603842027443081\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 716 , best gradient : 0.06333134191331181\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 717 , best gradient : 0.03277168000899494\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 718 , best gradient : 0.06243430794862839\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 719 , best gradient : 0.032611944342850134\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 720 , best gradient : 0.06219405163708174\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 721 , best gradient : 0.03248701673483022\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 722 , best gradient : 0.061955602181857375\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 723 , best gradient : 0.032362575919298475\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 724 , best gradient : 0.06171798808131105\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 725 , best gradient : 0.032238569816997985\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 726 , best gradient : 0.061481205467949857\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 727 , best gradient : 0.03211499708808226\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 728 , best gradient : 0.06124525191744175\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 729 , best gradient : 0.03199185647064618\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 730 , best gradient : 0.06101012501227109\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 731 , best gradient : 0.03186914670537563\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 732 , best gradient : 0.06077582233958789\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 733 , best gradient : 0.031746866535416925\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 734 , best gradient : 0.06054234149121495\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 735 , best gradient : 0.031625014706390384\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 736 , best gradient : 0.060309680063624645\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 737 , best gradient : 0.03150358996637176\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 738 , best gradient : 0.060077835657952015\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 739 , best gradient : 0.031382591065904054\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 740 , best gradient : 0.059846805879977205\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 741 , best gradient : 0.03126201675798562\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 742 , best gradient : 0.05961658834013942\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 743 , best gradient : 0.031141865798070247\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 744 , best gradient : 0.05938718065351857\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 745 , best gradient : 0.031022136944070362\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 746 , best gradient : 0.05915858043984368\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 747 , best gradient : 0.03094919797193814\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 748 , best gradient : 0.4146334298198599\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 749 , best gradient : 0.05051575438468264\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 750 , best gradient : 0.06006671239118782\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 751 , best gradient : 0.031033139729536766\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 752 , best gradient : 0.05908474103978305\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 753 , best gradient : 0.03087111118791687\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 754 , best gradient : 0.05885322542669377\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 755 , best gradient : 0.030750998937755958\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 756 , best gradient : 0.05862413600034749\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 757 , best gradient : 0.030631403845991917\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 758 , best gradient : 0.058395869030285125\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 759 , best gradient : 0.030512235951958455\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 760 , best gradient : 0.058168418604905625\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 761 , best gradient : 0.030393493777397314\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 762 , best gradient : 0.05794178224959758\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 763 , best gradient : 0.03038631557267826\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 764 , best gradient : 0.1407525521830677\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 765 , best gradient : 0.03444701279375467\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 766 , best gradient : 0.057291007470329544\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 767 , best gradient : 0.029868423132696355\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 768 , best gradient : 0.05692554237257723\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 769 , best gradient : 0.029745132762666254\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 770 , best gradient : 0.0567047818670985\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 771 , best gradient : 0.029629996885850402\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 772 , best gradient : 0.056485057648826824\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 773 , best gradient : 0.029515284170901452\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 774 , best gradient : 0.05626611726210701\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 775 , best gradient : 0.029400979918841507\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 776 , best gradient : 0.05604795790252441\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 777 , best gradient : 0.029287082873341308\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 778 , best gradient : 0.05583057720683017\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 779 , best gradient : 0.02917359180417465\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 780 , best gradient : 0.05561397281753334\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 781 , best gradient : 0.02911767753458062\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 782 , best gradient : 0.2089991289567821\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 783 , best gradient : 0.03487474154784464\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 784 , best gradient : 0.05171580481328116\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 785 , best gradient : 0.028192436482282198\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 786 , best gradient : 0.1599696161618361\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 787 , best gradient : 0.03229725460722161\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 788 , best gradient : 0.05164388924422335\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 789 , best gradient : 0.027939952132680385\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 790 , best gradient : 0.24922594125841777\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 791 , best gradient : 0.0369386496258965\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 792 , best gradient : 0.052784943092084424\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 793 , best gradient : 0.0284330928886158\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 794 , best gradient : 0.37709977096595676\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 795 , best gradient : 0.04369136406778908\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 796 , best gradient : 0.053060292719288873\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 797 , best gradient : 0.027935048457333515\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 798 , best gradient : 0.198646115632835\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 799 , best gradient : 0.03313286183604294\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 800 , best gradient : 0.050170230848272115\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 801 , best gradient : 0.027547236201359307\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 802 , best gradient : 0.15561092689603062\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 803 , best gradient : 0.031026992582640824\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 804 , best gradient : 0.05014942921488867\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 805 , best gradient : 0.02721891823380837\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 806 , best gradient : 0.24102971858388056\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 807 , best gradient : 0.03459450917842416\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 808 , best gradient : 0.12206600016022125\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 809 , best gradient : 0.029199302577404555\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 810 , best gradient : 0.11041125971545904\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 811 , best gradient : 0.028492539784245062\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 812 , best gradient : 0.1085345667718712\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 813 , best gradient : 0.02821797493385545\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 814 , best gradient : 0.10756211577249669\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 815 , best gradient : 0.027984718854102454\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 816 , best gradient : 0.10667874059137161\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 817 , best gradient : 0.027756781907174\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 818 , best gradient : 0.10580935764141733\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 819 , best gradient : 0.027530837386461587\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 820 , best gradient : 0.10494701016168366\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 821 , best gradient : 0.02730656956600303\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 822 , best gradient : 0.10409102283899006\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 823 , best gradient : 0.027083940727668315\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 824 , best gradient : 0.10324130048727345\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 825 , best gradient : 0.02703114996597944\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 826 , best gradient : 0.11876299551859608\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 827 , best gradient : 0.027232778462746104\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 828 , best gradient : 0.10254888278719206\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 829 , best gradient : 0.026484159956917212\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 830 , best gradient : 0.34295162390713274\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 831 , best gradient : 0.037255858899124084\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 832 , best gradient : 0.12350185773977078\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 833 , best gradient : 0.027415648950468947\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 834 , best gradient : 0.32995337846477796\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 835 , best gradient : 0.03699795668696274\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 836 , best gradient : 0.12381546735806337\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 837 , best gradient : 0.02933667966762656\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 838 , best gradient : 0.3282630794685047\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 839 , best gradient : 0.03635112307164451\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 840 , best gradient : 0.12208191398972322\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 841 , best gradient : 0.02745539951210351\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 842 , best gradient : 0.1034263396183042\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 843 , best gradient : 0.026978183217030768\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 844 , best gradient : 0.302400167737115\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 845 , best gradient : 0.03465650562612738\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 846 , best gradient : 0.11800325576421002\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 847 , best gradient : 0.027040277541054033\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 848 , best gradient : 0.10211312470965522\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 849 , best gradient : 0.026750404831444127\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 850 , best gradient : 0.21950701336892023\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 851 , best gradient : 0.030830967984546192\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 852 , best gradient : 0.1100446262381656\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 853 , best gradient : 0.026712681376425993\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 854 , best gradient : 0.10148169098225042\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 855 , best gradient : 0.026293983108596597\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 856 , best gradient : 0.1004112861394518\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 857 , best gradient : 0.0261485623164772\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 858 , best gradient : 0.09989532098989913\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 859 , best gradient : 0.02602379700913345\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 860 , best gradient : 0.09942214539223827\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 861 , best gradient : 0.025901048345742632\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 862 , best gradient : 0.0989539991598957\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 863 , best gradient : 0.025778937806415263\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 864 , best gradient : 0.09848808581416196\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 865 , best gradient : 0.02565736159737137\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 866 , best gradient : 0.09802419150617218\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 867 , best gradient : 0.025536310186518276\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 868 , best gradient : 0.09756229340932795\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 869 , best gradient : 0.02541578102727099\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 870 , best gradient : 0.09710238286840858\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 871 , best gradient : 0.025295772098136514\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 872 , best gradient : 0.09664445230623384\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 873 , best gradient : 0.02524830806963109\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 874 , best gradient : 0.28099884834607725\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 875 , best gradient : 0.031728896638065295\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 876 , best gradient : 0.1094382575831078\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 877 , best gradient : 0.02554770612829876\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 878 , best gradient : 0.09677512884559392\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 879 , best gradient : 0.02518922420164605\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 880 , best gradient : 0.33606918743162256\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 881 , best gradient : 0.03654337311773796\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 882 , best gradient : 0.12487315571173074\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 883 , best gradient : 0.028836462462759175\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 884 , best gradient : 0.10889449440805349\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 885 , best gradient : 0.028071352922260182\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 886 , best gradient : 0.10695662172354617\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 887 , best gradient : 0.027815274990553356\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 888 , best gradient : 0.10605107401819606\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 889 , best gradient : 0.02759790808582137\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 890 , best gradient : 0.10522652679332242\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 891 , best gradient : 0.027384756413077842\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 892 , best gradient : 0.10441317762811442\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 893 , best gradient : 0.027173278355432387\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 894 , best gradient : 0.10360586897730387\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 895 , best gradient : 0.026963279416738022\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 896 , best gradient : 0.10280419258417477\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 897 , best gradient : 0.026754737818424735\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 898 , best gradient : 0.10200808978249627\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 899 , best gradient : 0.02654764453294775\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 900 , best gradient : 0.10121752775795076\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 901 , best gradient : 0.02634199149543886\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 902 , best gradient : 0.10043247568660814\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 903 , best gradient : 0.02613777073356182\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 904 , best gradient : 0.09965290297338351\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 905 , best gradient : 0.025934974303201082\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 906 , best gradient : 0.09887877912193613\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 907 , best gradient : 0.025733594283734815\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 908 , best gradient : 0.09811007372520955\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 909 , best gradient : 0.025533622777737658\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 910 , best gradient : 0.0973467564649645\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 911 , best gradient : 0.02533505191097687\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 912 , best gradient : 0.09658879711189822\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 913 , best gradient : 0.025276263814762154\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 914 , best gradient : 0.20972795476897418\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 915 , best gradient : 0.028163897116727787\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 916 , best gradient : 0.09973045986076333\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 917 , best gradient : 0.024936903142971797\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 918 , best gradient : 0.1088943936759228\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 919 , best gradient : 0.0249326099355566\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 920 , best gradient : 0.2920027639785626\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 921 , best gradient : 0.030683877921151688\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 922 , best gradient : 0.04330031213597789\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 923 , best gradient : 0.02501921900155919\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 924 , best gradient : 0.28113563588764634\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 925 , best gradient : 0.02960584710718766\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 926 , best gradient : 0.04268948568298043\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 927 , best gradient : 0.023901353523158947\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 928 , best gradient : 0.15637139648274515\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 929 , best gradient : 0.024732716986340643\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 930 , best gradient : 0.09078143859461256\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 931 , best gradient : 0.024185524338259108\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 932 , best gradient : 0.31677110646156437\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 933 , best gradient : 0.030742632691076556\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 934 , best gradient : 0.10517366405427901\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 935 , best gradient : 0.02457236517829705\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 936 , best gradient : 0.20219015051122596\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 937 , best gradient : 0.026207500938444882\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 938 , best gradient : 0.09380176646409118\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 939 , best gradient : 0.023275295778956585\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 940 , best gradient : 0.19186692703781752\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 941 , best gradient : 0.02476958713937778\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 942 , best gradient : 0.08867593805648125\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 943 , best gradient : 0.02302760443465155\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 944 , best gradient : 0.15776542838724344\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 945 , best gradient : 0.0244259735117131\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 946 , best gradient : 0.04173768699435106\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 947 , best gradient : 0.023084104100629766\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 948 , best gradient : 0.2973349413935402\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 949 , best gradient : 0.027038216138570215\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 950 , best gradient : 0.09236356810186817\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 951 , best gradient : 0.023067370298982613\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 952 , best gradient : 0.2642913804277963\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 953 , best gradient : 0.02785571998766871\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 954 , best gradient : 0.042714013220239995\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 955 , best gradient : 0.022752633067261965\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 956 , best gradient : 0.25248946638811004\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 957 , best gradient : 0.026960663114153932\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 958 , best gradient : 0.04221922960999679\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 959 , best gradient : 0.0226577787968989\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 960 , best gradient : 0.18357315107700842\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 961 , best gradient : 0.024151874963923438\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 962 , best gradient : 0.08804007854261564\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 963 , best gradient : 0.02260599707971983\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 964 , best gradient : 0.10682163527210597\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 965 , best gradient : 0.02286514050241289\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 966 , best gradient : 0.08643551342461903\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 967 , best gradient : 0.022316745608981593\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 968 , best gradient : 0.08509289410239144\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 969 , best gradient : 0.022144814832509567\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 970 , best gradient : 0.0844644987404734\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 971 , best gradient : 0.022031602723120113\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 972 , best gradient : 0.27474552399632624\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 973 , best gradient : 0.026111822527802378\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 974 , best gradient : 0.09192127253738305\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 975 , best gradient : 0.02256226492935043\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 976 , best gradient : 0.2546231465150432\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 977 , best gradient : 0.0253148759966162\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 978 , best gradient : 0.040399434962888635\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 979 , best gradient : 0.02209520323162224\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 980 , best gradient : 0.18643583781132428\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 981 , best gradient : 0.023494868490555775\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 982 , best gradient : 0.0857123225254621\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 983 , best gradient : 0.02157207749924921\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 984 , best gradient : 0.19458545874956748\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 985 , best gradient : 0.02334774332647622\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 986 , best gradient : 0.24967403913251685\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 987 , best gradient : 0.023848385809340202\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 988 , best gradient : 0.0850010422934164\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 989 , best gradient : 0.021335655497702763\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 990 , best gradient : 0.18081830792350337\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 991 , best gradient : 0.022563602841331413\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 992 , best gradient : 0.08284309847609848\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 993 , best gradient : 0.021108853965959243\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 994 , best gradient : 0.18890809103949247\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 995 , best gradient : 0.021933702106994662\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 996 , best gradient : 0.08007804110027476\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 997 , best gradient : 0.021269729787473598\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 998 , best gradient : 0.23070400211265876\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n",
      "Iteration 999 , best gradient : 0.02243821866158252\n",
      "Number of new features: 0\n",
      "Number of features after pruning: 1261 , 0 features pruned\n",
      "Gradient Upper bounds : []\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8802816901408451\n",
      "Test accuracy: 0.9020979020979021\n"
     ]
    }
   ],
   "source": [
    "seql = SEQL(convergence_threshold=.002, max_iterations=1000, C=0)\n",
    "seql.fit(cancer_sax, y_train, plot_grads=True, verbose =True)\n",
    "\n",
    "print(\"Train accuracy:\", seql.score(cancer_sax, y_train))\n",
    "print(\"Test accuracy:\", seql.score(cancer_sax_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.\n",
      "  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1.\n",
      "  1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1.  1. -1.\n",
      " -1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1.\n",
      " -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(seql.predict(cancer_sax_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sax = np.array([SAX_window(ts, w=16, alpha=4, l = int(0.2*len(ts))+1 ) for ts in train['Music']])\n",
    "train_labels = np.array(train['Genre'])\n",
    "\n",
    "genres = np.unique(train_labels)\n",
    "genre_to_index = {genre : index for index, genre in enumerate(genres)}\n",
    "\n",
    "train_labels = [genre_to_index[label] for label in train_labels]\n",
    "\n",
    "test_sax = np.array([SAX_window(ts, w=16, alpha=4, l = int(0.2*len(ts))+1 ) for ts in test['Music']])\n",
    "test_labels = np.array(test['Genre'])\n",
    "\n",
    "test_labels = [genre_to_index[label] for label in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mseql_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     29\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m seql_pipeline\u001b[38;5;241m.\u001b[39mpredict(test_sax)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 469\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params)\u001b[0m\n\u001b[0;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1314\u001b[0m         )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m         )\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "# ChatGPT code, not even sure what this is\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Function to convert time series to SAX representation\n",
    "def time_series_to_sax(time_series, w, alpha):\n",
    "    return ' '.join(map(str, SAX_window(time_series, w, alpha, int(.2*len(time_series)+1))))\n",
    "\n",
    "# Convert the training and test data to SAX representation\n",
    "train_sax = [time_series_to_sax(ts, w=16, alpha=4) for ts in train['Music']]\n",
    "train_labels = train['Genre']\n",
    "test_sax = [time_series_to_sax(ts, w=16, alpha=4) for ts in test['Music']]\n",
    "\n",
    "# Filter out empty SAX representations and corresponding labels\n",
    "train_sax, train_labels = zip(*[(sax, label) for sax, label in zip(train_sax, train['Genre']) if sax.strip()])\n",
    "test_sax, test_labels = zip(*[(sax, label) for sax, label in zip(test_sax, test['Genre']) if sax.strip()])\n",
    "\n",
    "# Create a pipeline with CountVectorizer and LogisticRegression\n",
    "seql_pipeline = make_pipeline(\n",
    "    CountVectorizer(),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model\")\n",
    "seql_pipeline.fit(train_sax, train_labels)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = seql_pipeline.predict(test_sax)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = (test_predictions == test_labels).mean()\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U9'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 107\u001b[0m\n\u001b[0;32m    104\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])            \u001b[38;5;66;03m# Labels\u001b[39;00m\n\u001b[0;32m    106\u001b[0m seql \u001b[38;5;241m=\u001b[39m SEQL(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m \u001b[43mseql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest feature:\u001b[39m\u001b[38;5;124m\"\u001b[39m, seql\u001b[38;5;241m.\u001b[39mbest_feature)\n",
      "Cell \u001b[1;32mIn[70], line 67\u001b[0m, in \u001b[0;36mSEQL.fit\u001b[1;34m(self, sequences, y)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Traverse features to find the best gradient\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature, idx \u001b[38;5;129;01min\u001b[39;00m feature_map\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     66\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m---> 67\u001b[0m         \u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(y \u001b[38;5;241m*\u001b[39m (X \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta))))\n\u001b[0;32m     68\u001b[0m     ) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n\u001b[0;32m     69\u001b[0m     gradient \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_regularization_gradient(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta[idx])\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Update best feature\u001b[39;00m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U9'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "# ChatGPT code \n",
    "\n",
    "class SEQL:\n",
    "    def __init__(self, C=1.0, alpha=0.5, convergence_threshold=1e-5, max_iterations=1000):\n",
    "        self.C = C\n",
    "        self.alpha = alpha\n",
    "        self.convergence_threshold = convergence_threshold\n",
    "        self.max_iterations = max_iterations\n",
    "        self.beta = None\n",
    "        self.best_feature = None\n",
    "\n",
    "    def _compute_regularization_gradient(self, beta_j):\n",
    "        \"\"\"Elastic-net gradient.\"\"\"\n",
    "        return self.alpha * np.sign(beta_j) + (1 - self.alpha) * beta_j\n",
    "\n",
    "    def _compute_loss_gradient(self, X, y, beta):\n",
    "        \"\"\"Compute gradients for all features.\"\"\"\n",
    "        margins = y * (X @ beta)\n",
    "        probabilities = 1 / (1 + np.exp(margins))\n",
    "        gradients = X.T @ (y * probabilities) / len(y)\n",
    "        return gradients\n",
    "\n",
    "    def _prune(self, prefix_gradient, current_best):\n",
    "        \"\"\"Prune if the bound indicates no improvement.\"\"\"\n",
    "        return np.abs(prefix_gradient) < current_best\n",
    "\n",
    "    def _expand_features(self, sequences, feature_map):\n",
    "        \"\"\"Iteratively expand features from unigrams.\"\"\"\n",
    "        expanded_features = set(feature_map.keys())\n",
    "        for seq in sequences:\n",
    "            for i in range(len(seq)):\n",
    "                for j in range(i + 1, len(seq) + 1):\n",
    "                    feature = seq[i:j]\n",
    "                    if ' ' in feature:\n",
    "                        continue  # Skip features containing spaces\n",
    "                    if feature not in expanded_features:\n",
    "                        feature_map[feature] = len(feature_map)\n",
    "                        expanded_features.add(feature)\n",
    "        return feature_map\n",
    "\n",
    "    def fit(self, sequences, y):\n",
    "        \"\"\"\n",
    "        Fit SEQL model.\n",
    "        - sequences: List of input sequences.\n",
    "        - y: Binary labels (-1, 1).\n",
    "        \"\"\"\n",
    "        # Start with unigrams\n",
    "        feature_map = {char: idx for idx, char in enumerate(set(''.join(sequences)))}\n",
    "        X = np.zeros((len(sequences), len(feature_map)))\n",
    "\n",
    "        # Build initial feature matrix\n",
    "        for i, seq in enumerate(sequences):\n",
    "            for feature in feature_map:\n",
    "                X[i, feature_map[feature]] = seq.count(feature)\n",
    "\n",
    "        num_features = X.shape[1]\n",
    "        self.beta = np.zeros(num_features)\n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            best_gradient = 0\n",
    "            best_feature = None\n",
    "\n",
    "            # Traverse features to find the best gradient\n",
    "            for feature, idx in feature_map.items():\n",
    "                gradient = np.sum(\n",
    "                    y * X[:, idx] * (1 / (1 + np.exp(y * (X @ self.beta))))\n",
    "                ) / len(y)\n",
    "                gradient += self.C * self._compute_regularization_gradient(self.beta[idx])\n",
    "\n",
    "                # Update best feature\n",
    "                if np.abs(gradient) > best_gradient:\n",
    "                    best_gradient = np.abs(gradient)\n",
    "                    best_feature = feature\n",
    "\n",
    "            # Stopping condition\n",
    "            if best_gradient < self.convergence_threshold:\n",
    "                print(\"Converged after\", iteration, \"iterations.\")\n",
    "                break\n",
    "\n",
    "            # Update selected feature\n",
    "            idx = feature_map[best_feature]\n",
    "            step_size = best_gradient  # Simplified; refine with line search if needed\n",
    "            self.beta[idx] -= step_size\n",
    "\n",
    "            # Expand feature map iteratively\n",
    "            feature_map = self._expand_features(sequences, feature_map)\n",
    "            new_X = np.zeros((len(sequences), len(feature_map)))\n",
    "            for i, seq in enumerate(sequences):\n",
    "                for feature in feature_map:\n",
    "                    new_X[i, feature_map[feature]] = seq.count(feature)\n",
    "            X = new_X\n",
    "            self.beta = np.zeros(len(feature_map))\n",
    "\n",
    "        self.best_feature = best_feature\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using the learned model.\"\"\"\n",
    "        return np.sign(X @ self.beta)\n",
    "\n",
    "# Example usage\n",
    "# Sequences should exclude spaces during preprocessing.\n",
    "sequences = [\"abc\", \"ab\", \"bc\"]  # Example sequences\n",
    "y = np.array([1, -1, 1])            # Labels\n",
    "\n",
    "seql = SEQL(C=1.0, alpha=0.5)\n",
    "seql.fit(train_sax, train_labels)\n",
    "print(\"Best feature:\", seql.best_feature)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
