{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import IPython\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "os.chdir(\"F:\\M2\\Interpretable-TimeSeries-Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melvi\\AppData\\Local\\Temp\\ipykernel_2880\\2820360306.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  music_time_series, sr = librosa.load(dataloc + genre + \"/\" + music)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading jazz.00054.wav: \n",
      "Creating dataframe\n",
      "Saving dataframe\n",
      "Saving train and test data\n"
     ]
    }
   ],
   "source": [
    "dataloc  = \"Data/genres_original/\"\n",
    "\n",
    "genres = os.listdir(dataloc)\n",
    "\n",
    "musiclist = []\n",
    "genrelist = []\n",
    "srlist = []\n",
    "\n",
    "musictrain = []\n",
    "genretrain = []\n",
    "srtrain = []\n",
    "musictest = []\n",
    "genretest = []\n",
    "srtest = []\n",
    "\n",
    "print(\"Reading songs\")\n",
    "for genre in genres:\n",
    "    for i, music in enumerate(os.listdir(dataloc + genre)):\n",
    "        try:\n",
    "            music_time_series, sr = librosa.load(dataloc + genre + \"/\" + music)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {music}: {e}\")\n",
    "            continue\n",
    "        srlist.append(sr)\n",
    "        musiclist.append(music_time_series)\n",
    "        genrelist.append(genre)\n",
    "\n",
    "        if i<25: # 25-75 test train split\n",
    "            musictest.append(music_time_series)\n",
    "            genretest.append(genre)\n",
    "            srtest.append(sr)\n",
    "        else:\n",
    "            musictrain.append(music_time_series)\n",
    "            genretrain.append(genre)\n",
    "            srtrain.append(sr)\n",
    "\n",
    "print(\"Creating dataframe\")\n",
    "fulldata = pd.DataFrame({'Music': musiclist, 'Genre': genrelist, \"SampleRate\": srlist})\n",
    "\n",
    "print(\"Saving dataframe\")\n",
    "fulldata.to_csv(\"Data/fulldata.csv\", index=False)\n",
    "\n",
    "print(\"Saving train and test data\")\n",
    "train = pd.DataFrame({\"Music\" : musictrain, \"Genre\" : genretrain, \"SampleRate\": srtrain})\n",
    "test = pd.DataFrame({\"Music\" : musictest, \"Genre\" : genretest, \"SampleRate\": srtest})\n",
    "\n",
    "with open(\"Data/train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train, f)\n",
    "\n",
    "with open(\"Data/test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/train.pkl\", \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(\"Data/test.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAX Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = np.array([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"])\n",
    "\n",
    "def SAX(time_series, w, alpha):\n",
    "    time_series = np.array(time_series)\n",
    "    time_series = (time_series - np.mean(time_series)) / np.std(time_series)\n",
    "\n",
    "    # PAA\n",
    "    PAA=[]\n",
    "    for word_index in range(w):\n",
    "        ceiling = min(len(time_series), int((word_index+1)*len(time_series)/w))\n",
    "        PAA.append(np.mean(time_series[int(word_index*len(time_series)/w):ceiling]))\n",
    "    \n",
    "    lookup = np.quantile(time_series, np.arange(1,alpha)*(1/alpha) )\n",
    "    \n",
    "    sax = np.digitize(PAA, lookup)\n",
    "\n",
    "    return list(sax)\n",
    "\n",
    "def SAX_window(time_series, w, alpha, l):\n",
    "    L = len(time_series)\n",
    "    sax_sentence = []\n",
    "    previous_word = np.full(w,-1)\n",
    "\n",
    "    for i in range(0, L, l):\n",
    "        print(i)\n",
    "        ceiling = min(L, (i+1)*l)\n",
    "        sax_word = SAX(time_series[i : ceiling], w, alpha)\n",
    "\n",
    "        npsaxword = np.array(sax_word)\n",
    "        if np.sum(npsaxword - previous_word) == 0: # Remove repeated words for reasons\n",
    "            continue\n",
    "        \n",
    "        if i > 0:\n",
    "            sax_sentence.append(\" \")\n",
    "        sax_sentence.extend(sax_word)\n",
    "        if ceiling == L: break # Do not take <L sized sequences into account\n",
    "        previous_word = sax_word\n",
    "\n",
    "    phrase = \"\"\n",
    "    for letter in sax_sentence:\n",
    "        if isinstance(letter, np.int64):\n",
    "            phrase += alphabet[letter]\n",
    "        else :\n",
    "            phrase += letter\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 10 20 30 40 50 60 70 80 90]\n"
     ]
    }
   ],
   "source": [
    "print(np.arange(0,100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "132359\n",
      "cbccbbcbccbbccbb cccccccccccccccc\n"
     ]
    }
   ],
   "source": [
    "nptrainmusic = train[\"Music\"].to_numpy()\n",
    "\n",
    "testmusic = nptrainmusic[19]\n",
    "\n",
    "# Pre-process eliminating noise\n",
    "#testmusic = librosa.effects.preemphasis(testmusic)\n",
    "\n",
    "sentence = SAX_window(testmusic, w = 16, alpha = 4, l = int(.2*len(testmusic)+1 ))\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 4\n",
    "w , halfw= 4, 2\n",
    "\n",
    "DFT_base_length4 = np.empty((len(nptrainmusic), w))\n",
    "\n",
    "for i, music in enumerate(nptrainmusic):\n",
    "    fft = np.fft.fft(music)\n",
    "    halfw_real = np.real(fft[:halfw])\n",
    "    halfw_complex = np.imag(fft[:halfw])\n",
    "    \n",
    "    DFT_base_length4[i] = np.array([halfw_real[0], halfw_complex[0], halfw_real[1], halfw_complex[1]]) # Shitty inefficient, can be made with np.apply_along_axis\n",
    "\n",
    "q =  np.arange(1,alpha)*(1/alpha)\n",
    "\n",
    "SFA_breakpoints = np.quantile(DFT_base_length4, q, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SFA(time_series, alpha=alpha, w=w, lookup=SFA_breakpoints):\n",
    "    fft = np.fft.fft(time_series)\n",
    "    halfw = w//2\n",
    "    halfw_real = np.real(fft[:halfw])\n",
    "    halfw_complex = np.imag(fft[:halfw])\n",
    "    coefs = np.array([halfw_real[0], halfw_complex[0], halfw_real[1], halfw_complex[1]])\n",
    "\n",
    "    sfa=np.empty(w, dtype=np.int64)\n",
    "    for i, coef in enumerate(coefs):\n",
    "        sfa[i] = np.digitize(coef, lookup[:,i]) * (i+1) # *(i+1) to make sure same indices for different coefficients don't get the same symbol\n",
    "\n",
    "    return sfa\n",
    "\n",
    "def SFA_window(time_series, l, alpha=alpha, w=w, lookup=SFA_breakpoints):\n",
    "    L = len(time_series)\n",
    "    sfa_sentence = []\n",
    "    previous_word = np.full(w,-1)\n",
    "\n",
    "    for i in range(0, L, l): # Non-overlapping windows for this one\n",
    "        ceiling = min(L, (i+1)*l) \n",
    "        sfa_word = SFA(time_series[i : ceiling], w, alpha, lookup=lookup)\n",
    "\n",
    "        npsfaword = np.array(sfa_word)\n",
    "        if np.sum(npsfaword - previous_word) == 0: # Remove repeated words for reasons\n",
    "            continue\n",
    "        \n",
    "        if i > 0:\n",
    "            sfa_sentence.append(\" \")\n",
    "        sfa_sentence.extend(sfa_word)\n",
    "        previous_word = sfa_word\n",
    "\n",
    "    phrase = \"\"\n",
    "    for letter in sfa_sentence:\n",
    "        if isinstance(letter, np.int64):\n",
    "            phrase += alphabet[letter]\n",
    "        elif letter == \" \":\n",
    "            phrase += letter\n",
    "        else:\n",
    "            raise ValueError(\"error, got letter\", letter)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcde degi dade dede dege\n"
     ]
    }
   ],
   "source": [
    "selected_index = 161\n",
    "selected_music = nptrainmusic[selected_index]\n",
    "\n",
    "print(SFA_window(selected_music, l=int(.2*len(selected_music+1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mseql_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     29\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m seql_pipeline\u001b[38;5;241m.\u001b[39mpredict(test_sax)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 469\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params)\u001b[0m\n\u001b[0;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1314\u001b[0m         )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m         )\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "# ChatGPT code, not even sure what this is\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Function to convert time series to SAX representation\n",
    "def time_series_to_sax(time_series, w, alpha):\n",
    "    return ' '.join(map(str, SAX_window(time_series, w, alpha, int(.2*len(time_series)+1))))\n",
    "\n",
    "# Convert the training and test data to SAX representation\n",
    "train_sax = [time_series_to_sax(ts, w=16, alpha=4) for ts in train['Music']]\n",
    "train_labels = train['Genre']\n",
    "test_sax = [time_series_to_sax(ts, w=16, alpha=4) for ts in test['Music']]\n",
    "\n",
    "# Filter out empty SAX representations and corresponding labels\n",
    "train_sax, train_labels = zip(*[(sax, label) for sax, label in zip(train_sax, train['Genre']) if sax.strip()])\n",
    "test_sax, test_labels = zip(*[(sax, label) for sax, label in zip(test_sax, test['Genre']) if sax.strip()])\n",
    "\n",
    "# Create a pipeline with CountVectorizer and LogisticRegression\n",
    "seql_pipeline = make_pipeline(\n",
    "    CountVectorizer(),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model\")\n",
    "seql_pipeline.fit(train_sax, train_labels)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = seql_pipeline.predict(test_sax)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = (test_predictions == test_labels).mean()\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cccbccccbcbcccbc cccbcccccccccccc cccccccccccccccc bcbcbccbcccbcccb'\n",
      " 'cbccbbcbbbbbbbbb bbbbbbbbbbccbbbc bbbbbbbbcbbbbbbb cbbbcbbbbbbbbcbb'\n",
      " 'cbcbbcbcbbcbcbcb cccccccccccccccc ccbbccbbccbbbbcb cccccccccccccccb bbbcbbcbbcbcbbbb'\n",
      " 'cccccccccccccccc' 'cbccbccbccbcbccb bbbbbbbbbbbbbbbb bccbbcbccbcbbbbc'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc' 'bbcbbbbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbcbbbbbbcbbbcbb' 'bbbbbbbbbbbbbbbb cbbbbcbccbcbbbcb'\n",
      " 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'cccbccbcbccbcccb bbbbbbbbbbbbbbbb bbbcbcbbbbcbbbcb bbbbcbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb' 'bbbbcbbbbcbbbcbb bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc cbcccccbcccbcccb'\n",
      " 'cccccccccccccccc cbcbcbbbcbccbccc ccbccbccbbccccbc'\n",
      " 'bcccccccccbccccc bbbbbbbbbbbbbbbb cccbcccccccccccc' 'cccccccccccccccc'\n",
      " 'cbccbbcbccbbccbb cccccccccccccccc'\n",
      " 'bccbbbcbcbcbbcbc bbbbbbbbbbbbbbbb cbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb bbbbcbbbbbbcbcbb'\n",
      " 'bcbcbccbcbbccbbb cccccccbccbccbbc cbbbbbbbbbbbbbbb ccccccccccbccccc cccccccccccccccc'\n",
      " 'ccccbccccccccccc cccccccccccccccc' 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbcbbcbbccbcb bbbbbbbbbbbbbbbb' 'bbbbccbbbcbbcbcb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbcbbbbbcbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'cbbbbbcbbbccbbbb bbbbbbbbbbbbbbbb bbcbcbbbbcbbbcbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbcbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'cbcccbccbcbcccbc cbcccccccccccccc cccccccccccccccc cccbbcccccbccccc'\n",
      " 'cccccccccccccccc ccbcccbcbccbccbc cbbbbcbcbbbbccbb bbbbbbbbbbbcbbcb bbbbbbbbbbbbbcbb'\n",
      " 'bbcbbbbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bcbccbcbbcbcbcbb ccbcbcccbbbccbcc cbbbcbcbbcbccbbc bcbcbbccccbbccbc'\n",
      " 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbcbbbbbbb ccccccccbccccbcc cbbcbbbcbcbcbbcb bbbcbbcbcbbbbbcb ccbccbcbcbcbcbbc'\n",
      " 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb ccccccccbccccccc'\n",
      " 'bbcbbbcbbcbbbbcb bbbbbbbbbbbbbbbb bbbbbbbbbbcbbcbb cbcbcbbbbbbcbcbb'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb' 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc bbbcbbbbbbbbbbbb bbbbbbbbbbbbbbbb bbcbccccbccccccc'\n",
      " 'cbcbbccbbccbcccb bbcbbcbbcbcbcbbb cbbbbbcbbbcbbcbb bcbbbbbbbbbbbbbb cbbbbcbcbbbcbbbb'\n",
      " 'ccccccccccccbccc cccccccccccccccc cccccccccccccbcb cbcbbcccbccccccb bccbcccbcbcbccbb'\n",
      " 'cccbcbcccccbcbbc bbbcbbbcbcccccbc bbbbbbcccccccbcc bcccccccccccbccc ccccbcccbbcbcccb'\n",
      " 'cccccccccccccccc' 'bbbbbcbbbbbbbbbc bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'cccccbcbcbcccccb bcbbcbccbbbcbbbb bbcccbbbbcbbbbbb cbbccccbcbcbbccb ccbccccbcccccccc'\n",
      " 'cbbbbbcbbbccbcbb bbbbbbbbbbbbbbbb bcbbbbbbbccbbbcb'\n",
      " 'bccbbccbbcbbbccb bbbbcbbbbbbbbbbb cbbccbbbbcbcbbbc cbbccccccccbcccc bbcbbbbbccbbbbbc'\n",
      " 'cccccccccccccccc'\n",
      " 'cbcccbcccccccccb cccccccccccccccc ccbccccccccccccc bcccccbccbccbccc'\n",
      " 'cbbcbbbcbcbcbbcb bbbbbbbbbbbbbbbb bbbbbbbbbcbbbbbb bcbcbbcbbbbbbbbb bccbbcbbbbbccbbc'\n",
      " 'bcbbbbbcbbbbcbbb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccb cccccccccccccccc cccbcccccccccccc'\n",
      " 'cccccccccccccccc'\n",
      " 'cccccccbcccbcccc cccccccccccccccc bbbbcccbcbcccbbc cccccccccccccccc cccbbcccccbccccc'\n",
      " 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc' 'cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbcb cccccccccccccccc'\n",
      " 'cbcbbbbbbbbbbbbb bbbbcbbcbbbbbcbb ccbcccccbccccbcc ccbcccccccccbccc bbcbcbccbbcbcbcb'\n",
      " 'ccbccccccccccccb cccccccccccccccc ccccbccccccccccc bcbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc' 'cccccccccccccccc' 'bbbbbbbbbbbbbbcb bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc bcbbbbbcbbbbbbbb'\n",
      " 'bbbbbbbbbcbbbcbb cccccccccccccccc ccccccccccbccccc'\n",
      " 'cbcccccccccccbcc cccccccccccccccc ccccccbcbccccccc bbccbccbbbbcbcbb'\n",
      " 'bbbbbbbbbbbbbbbb cbccccccccccccbb bbcbbbbcbbbbbbcb cccccccccccccccb cbbcbbbbbbcbcbbc'\n",
      " 'bbbbbbbbcbcbbbbb bcbbbbbbbbbbbbbb bbbbbbbbbbbbbbbb bbcbbcbbbbcbbbcc ccccccbcbccccccc'\n",
      " 'bbcbbbbbcbbbbcbb ccbcccccbccbcccc cbbcbbcbcbcbbbcb cccccccccccccccc cbccccbccccccccc'\n",
      " 'ccccbccbcccbccbc cccccccccccccccc'\n",
      " 'bbbbcbcbcbcbcbcb cccccccccccccccc ccccccbbcbbbbcbb cbbbccbbbbbbcbbb bcbbbbcbcbbbbbbb'\n",
      " 'ccccbccccccbcbcb cccccccccccccccc ccccbccccccccccc cccccccccccccbbb'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc bbbbbbbbbbbbbbbb cccccccccccccccc bccccccbcccccbcb'\n",
      " 'ccccccccccbccccc cccccbbccccccccc cbbbbbbccbbbbbbb ccccccccbccccccb'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb bcbccccccccbcbcc'\n",
      " 'cbbcbbbcbbbbbbcb bbbbbbbbbbbbbbbb bcbcbcbcbbbcbccb'\n",
      " 'bcbbbbbbbbbbbbbb bbcbbbbbcbcbccbb bbbbbbbcbbbbcbbb bbbbbbbbbcbbbbbb'\n",
      " 'bccbccbcccbcbccb cccccccccccccccb cccccccccccccbbb cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbcbbb bbbbbbbbbbbbbbbb cbcbcbbcbbbbbcbb'\n",
      " 'bcbbbcbbcbbcbbcb bbbbbbbbbbbbcbbb cbbcbbbbbcbbbccb cbbbbbbbbbbbbcbb'\n",
      " 'bbcbbbccbcbbbcbc bcbccccccccccccc cccccccccccccccc bccccbcccbcccccc bcbbbbbbcbcbbcbb'\n",
      " 'cbcccccbcccccccb cbbbcbbbbbbcbbbb bcbbbbbbbbcbbbbb bbbcbbbbbbbbbbbb cbbcbbcbbcbcbbcc'\n",
      " 'cccbcccccbcccccc cccccccccccccccb cbcccbccbccccccb bbcbbcbccbccbcbb'\n",
      " 'cbbcccbbbcccbccc cccccbccccccbccc cccccccccccccccc bbbbbbbbbbbbbbbb bbbcccbbbbcbcbcc'\n",
      " 'bbbbbbbbbbbcbbbb bbbbbbbbbbbbbbbb cbbccbbbbbcbbbbb'\n",
      " 'bbcbbbbcbbcbbcbb cccccccccccccccc bccbbbccbcccbbcb bcccbcccbcbbbcbc cbcbcbbcbbcbbbcc'\n",
      " 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc bbbbbbbbbbbbbbbb'\n",
      " 'cbccccccbcbccbbc bcbcbbcccbbbcbbb bbbccbbbbbbcbbcb bbccbbbbbbbccbcb'\n",
      " 'bcbbcccccbcbbcbc cccccccccccccccc ccccccccccbccccc ccccbcccccccbccc'\n",
      " 'ccbcbcccccccbccc bbbbbbbbbcbcbccb bcbbcbbcbcbccbcb cbcbbcccbcbcbcbb bccbbcccbbccbccb'\n",
      " 'cccbcbbbcbbbbccb cccccbcbccbbccbb bccbcccccbcccbbc'\n",
      " 'ccccbcccbccccccc bbbbbbbcbbbbbbbb bbbbcbbbbcbbbbbb bbbbbbbbbbbcbbbb'\n",
      " 'bcbbcbcbbccbcccb bbbbbcbcbbcbbcbb bbbcbbbbbbbbbbbb bcbbbcbbbbbbbbbb'\n",
      " 'bbcccbbccbbbcccc bbbbbbbbbcbbbbbc bbbbbbbbbbbbbbbb bbbbbbbbbbbbbbcb bbbbbbbbbbbbbbbb'\n",
      " 'bbccbbbbbbbcbbcb bcbbbbbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbcbbbbbbb cccccccccccccccc bcccccccbccccccc ccccbccccccccccc bbbbbbbbbbbbbbbb'\n",
      " 'bbbcbcbbbbbbbbcb bbbbbbbbbcbbbbbb bbbbbbccccbbbbbb cbcccbcbbbbbbbcb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbccccccccbccccc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbbbbbcccc bbbbbcbcbbcccccc bbbbbbbbbbcccccc'\n",
      " 'bbbbbbbbbbbbbbbb bbcccbbbbbbbbbbb bbbbbbbbbbbbbbbb bbbbbbcbbbbcbbbb'\n",
      " 'ccccccccccccccbc cccccccccbbbbbbb cccccccbbbcbbbbb ccbbccbbcbbccbbb cbbcccccccccbccc'\n",
      " 'cbcccccccbcbcccc bbbbbbcbbbbbbbbb bbccbbbbbbbbbbbb ccccccccbccbbbbb bcccccbccbbbbbbb'\n",
      " 'ccccccbbbbbbbbbb bbbbbbbbbbccccbb bbbbbbbbcccccbbb ccccccbbbbbbbbbb'\n",
      " 'ccccccccbbbbccbb bbbbbbbbbccccbbb bbbbbbbcccccbbbb bbbbccccbbbbbbbb ccccccbbbbbbccbb'\n",
      " 'cccccccccccccccc ccccccccccccbbbb cbbcccccccbbbbbb'\n",
      " 'bbbbcccccccccccc cccccccccccccbbb cbcccccccccccbbb ccccccccbccbbbbb'\n",
      " 'cccbbbbbbbbbbbbb cccccccccbcbbbbb' 'cbbbbbcbcbcbcbcb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc bcbcccccbcccbcbc bcbcbcbcbccccbcc'\n",
      " 'bbbbbbbbcbbbbbbb cbcbbbcbcbcbcbbc bbbbbbbbbbbbbbbb cbcbcbcbcbbbbbbc'\n",
      " 'cccccccccccccccc ccbcccccbcbccbcb ccbcbcbbbbcbbbbb cbbcccbccccccccb cbcbcbcbccbcbcbb'\n",
      " 'cbbbbbbcbcbbccbb cccccccccccccccc bccccbcccccccccc bbbbbcbcbbbcbbbc bbcbcbbcbbbcbbbc'\n",
      " 'bbbbbbbbbbbbbbbb bbcbbbbcbbbcbbbb'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc cbccbcbbccbcbbcc cccccbcccbcbcbcc'\n",
      " 'bbbcbcbcbcbcbcbb cccccccccccccccc ccccccbccccccccc cccccccccccccccc ccccbccbcbcbcccb'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb bcbbbccbcbcbccbc ccbbccbcbccccbcc cbcbcbcccccbcccc'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc cccccccccccbcccc'\n",
      " 'cccccccccccccccc bccccbcbccbcbccc bcccbccccccbcccc cbcbcccccbccbccc'\n",
      " 'cccccccccccccccc bbbcbccbbcbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbbbbbbbcb bbbbbbbbbbbbbbbb'\n",
      " 'cbbbbbbbbbbbbbbb cccccccccccccccc ccccbcbcbccbccbc cccccccccbccbccc ccccccccccccccbc'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc' 'bbbbbbbbbbbbbbbb cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb cbcccccccccccccc cccccccccccccccc bbcbbcbcbcbcbbbc bbbbbbbbbbbbbbbb'\n",
      " 'ccccbccccbcccccc cccccccccccccccc bccbccccccbcbcbc' 'cccccccccccccccc'\n",
      " 'cccccccccccccccc' 'ccbcbccccccccccc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb cbbcbbccbcbbbcbc bccbcccccbcbccbc ccccbccccccccbcc cccccccccccccccc'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb cbbccbccbcbbbcbc cbccbcccccccbccb'\n",
      " 'cccccccccccccccc cccccccccccccbcc' 'cbbcbcbccbcbcbcc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbcbbbcbcbcb ccbbcccbccbcbcbc'\n",
      " 'bbbbbbbbbcbbbbbc bbbbbcbcbbbbbcbb bbcbcbbbbbcbcbcb bbbbbbbcbbbcbbcb cbbbbcccbbbcccbb'\n",
      " 'cccccbcccccccccc bbbbbbbbcbbbbbcb bcbbbccbbbbbbccb ccbbcbbbbbbbcccc cccbcccccbcccccc'\n",
      " 'cccccccccccccccc cccccccbcccccccc cbbcbccbcccbcccc ccccccbccccccccc'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb bbbbbbbccbcccbbb bccbccbcbcccbbcb bcccccccbccbccbc'\n",
      " 'cbcbbcbbcbccbbcb bbbcbbbbcbbbbbbc ccccbcbcbbcbcccc'\n",
      " 'bbbbbbbcbbbbbbbc bbbbcbcbbcbbbbbb ccbcbcbbbcbbcbbb cbbcbbcbbbbbcbcb cbcbcbcbccbcbcbc'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb' 'cccccccccccccccb bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'ccccccbccccccccc cccccccccccccccc' 'cccccccccccccccc'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc'\n",
      " 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc'\n",
      " 'cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb cbccbccccccbccbc cccccccccccbcccc ccccbcccccccbccc cbcbccccbccccccc'\n",
      " 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbcbbcbbccbcbbcb cbbcbbbbcbbbbbcb ccccccccbccbcccc bccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb cbcccccccccccccc cccccccccccccccc cccccccccccccccb'\n",
      " 'cccccccccccccccc' 'cccccccccccccccc' 'cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc' 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbcbcbbcbccbcbbc ccbccbbccbcbccbc bcbbbcbbbbbccbcc'\n",
      " 'bcbbcbbcbbbccbbc bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb cccccbbcbbcbccbc cccbcbcbccccbccc bbbbbcbbcbbcbbcb bbbbbbbbbbbbbbbb'\n",
      " 'cccbcccccccccccc cccccccccccccccc'\n",
      " 'cccccbcccccbbcbc cccccccccccccccc cccccccbcccccccc' 'cccccccccccccccc'\n",
      " 'cccccccccccccccc cccccccccccccccb cccccccccccccccc'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb ccbccbccbccccccb bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb'\n",
      " 'bbcbbcbbbbbbbbbb cccccccccbccbccc bbcbbbbbbcbbbbbb bbbbbbcbbbbbbbbb'\n",
      " 'cccccccccccccccc' 'cccccccccccccccc ccccccccccccbccc' 'cccccccccccccccc'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbc bbbbbbbbbbbbbbbb cbbcbbbbbbbbbbbb cccccbccccbccccc'\n",
      " 'cccccccccccccccc' 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bcbbbcbbbcbbbccb cccccccccccccccc'\n",
      " 'bbbcbbcbbbbbbbbb ccccbcbcbcccbbcb cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb cccccccbccccbccc bbbbbbbbbbbbbbbb' 'cccccccccccccccc'\n",
      " 'cccccccccccccccc bbbbbbbbcbbbcbcb' 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbcbbb bbbbbbbbbbbbbbbb'\n",
      " 'cccccbcccccbcccc bbbbbbbbbbbbbbbb bbbbbbbbbbbbbbcb bccbbbbccbcbbcbb'\n",
      " 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb cccbcbcccbcbccbc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb bcbbcbbcbbcbcbcc' 'bbbbbbbbbbbbbbbb'\n",
      " 'cbcbbbbcbbccbcbb cccccccccccccccc' 'bbbbbbbbbbcbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc bbbbbbbbcbcbbcbc' 'cccccccccccccccc'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb cbcbcbcccccccccc'\n",
      " 'cccccccccccccccc bcbbbbbbbbbbbbbb bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc'\n",
      " 'cccccccccccccccc bbcbbbbbcbcbbbbb bcbcbccbcbcbccbc bbbbbcbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc cccccbccccccccbc' 'bbbbbbbbcbcbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bcbbbbbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbcbbbbbbbb bbbccbbbccbcbcbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'cbbbbbbbbbbbbbbb bbbbbbbbbbbbbbbb' 'cbccbcccbccccccc cccccccccccccccc'\n",
      " 'cbcccbcbccccccbb cccccccccccccccc' 'ccbccccccccccccc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb ccbcccbcccbccccc cccccccccccccccc ccccbccccccccccc bbbbbbbcbbbbbbbb'\n",
      " 'cccccccccccccccc' 'cccccccccccccccc ccccbcbcbccbcccc cbcccccbcbcccccc'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc ccbccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'bccccccccccccccc ccccccccccbccccb ccccbccccccbccbc'\n",
      " 'bcbbbbbbbbbbbbcb bbbbbbbbbbbbbbbb bbbbcbbbbbcbbbbb'\n",
      " 'cccccccccbcccccb bcbbbbbbccbcbbbc cccbcccccccccccc bccbbccccbcbbccc'\n",
      " 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb cccccccccccccccc'\n",
      " 'ccbcccccccbccccc ccccbbccbccccccc cccccccccbcccccb bbcbcbcbbbbbcbbb'\n",
      " 'cccccccccccccccc' 'bcbcccbcbcbbcccb bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'bccccbcccccbcbcc cccccbccbccccccc bbbbbbbbbbbbbbbb bbbbbbbbcbbbbbbb bcbbbbbbbbbcbbbc'\n",
      " 'cccccccccccccccc ccccccccbccccccc' 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb'\n",
      " 'bcbbbcbbbbbbbbcb bbbcbbbbbbbbbbbb bbbcbbbbbbcbbcbb cbbcbcbbcbbbbbcb'\n",
      " 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb bbbbbbbbbbbbbbbc'\n",
      " 'bbcbbbbbbbbbcbbb bbbbbbbbbbbbbbbb'\n",
      " 'cccbccccbbcccccc cbbcbcbbbbcbbbcb bcbbbbcbbcbbbcbb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbcccccbccccbcbb ccbcccccccbbcccb cccccccbcbcbcbcb ccbccccbccbccccb'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc ccccccccccccbccc'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc ccbcccbccccccbcc'\n",
      " 'bcbbccbbcbbcbbbb bbbbbbbcbbbbbbbb bbbbcbccbbbcbcbb bcbcbbbbbbbbcbbb bcbcbbbbcbcbbbbb'\n",
      " 'cccccccccccccccc cccbccccccbccccc ccccccccccccbccc cccbcbcccccbcccc cccccccccccccccc'\n",
      " 'ccbcbbbbbbbcbbcb cccccccccccccccc ccccccccbcccbccc'\n",
      " 'bccbbccccccbcccc bbbbbbbbbbbbbbbb bbbbbbbbbbbbbbcb'\n",
      " 'cbcccbbccccbcccb cccccccccccccccc' 'cbccccccccbccccb cccccccccccccccc'\n",
      " 'bccccccccccccccc cccccccccccccccc cbcccccccccccccc' 'cccccccccccccccc'\n",
      " 'cbccccccbccccccc cccccccccccccccc ccccccbccccccbcb'\n",
      " 'bbbcbbbbbcbbbbbb cccccccccccccccc cccbcccccccccccc cbcccccccbcccccb ccbccccccccccccc'\n",
      " 'cbcbbcbcbccbcbcb cccccccccccccccc bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbcbbbcbbbbbbb'\n",
      " 'cccccccccccccccc bccbcccccccccccc cccccccccccccccc ccccccbccccbccbc'\n",
      " 'bbbbbbbbbbbbbbcb bbbbbbbbbbbbbbbb bbbbbbbcbbbbbbbb bbbbbbbbbbbbbbbb bbbbbbbbbbbbbbcb'\n",
      " 'cccccbccbcbccccc cccbbcccbccbcbcc cccccbcccccccbcc bccccccbccccbccb cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbcccbbcccc bccbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbc bbbbbbbbbbbbbbbb cbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbcbbc bbbbbbbbbbbbbbbb' 'ccccbccccccccccc cccccccccccccccc'\n",
      " 'cbbbbbbbbbbbbbbb cbccccccccbcbccb cccccccccccccccc cccccccccccccccb'\n",
      " 'cbccccccccccccbc cccccccccccccccc' 'cccccbcccccccccc bbbbbbbbbbbbbbbb'\n",
      " 'bccccccbccbccbcc cccccccccbcccccc ccbbcccccccccccc bbbbbcbbcbcbcbcb'\n",
      " 'bbbbbbbbbbbbbcbb bbbccccbcccbbccb bcccbbccbbbbbccb bbbbbbbbbbbbbbbb bcbbbbbccbcbcbbb'\n",
      " 'bcccbccbcbbccbcc bbbbbbbbbbbbbbbb bbbbbbbbbbbbcbbb bbbbbcbbcbbbbbbb'\n",
      " 'bcbbcbccbcbcbbcc bbbbcbbbbbcbbbbb bbbbcbbcbbbbbbcb bcbcbcbcbcbcbcbc'\n",
      " 'cccccccccccccccc'\n",
      " 'bbccbcbccbccbcbb cccbcbbcbbccbcbc bccbccbcbccccbcc bcbcbccbcbbbcbbb'\n",
      " 'ccbccbcbbccbcbcb bbbbbbbbbbbbbbbb bcbbbcbbbbbbbbbb bbbccbcbcbbbbbbb'\n",
      " 'cbccbbccbbbbcbbc cccccccccccccccc ccccbccccccccccc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbcbbbbbbbbb bbbbbbbbbbbbbbbb bbbbbbbbbbbbbbbc'\n",
      " 'bbbbcbbbbbbbbbbb bbbbbbbbbbbbbbbb bbcbbbbbbbbbbbbb bbcbbcbcbcbbcbcb'\n",
      " 'cccccccbccbccccc cccccccccccccccc bbccbccccccccbcc'\n",
      " 'bbcbbbbccbcccbcc bccbcbbbbbbbbbbb bbbbbbbbbbbbbbbb ccccccccccccbccc'\n",
      " 'cccccccccccccccc ccbccbcccccccccb'\n",
      " 'bbbbcbcbbbbbcbbc bbbbbbbbbbbbbbbb bcbbbbbbbcbbbbcb'\n",
      " 'bcbbbbbbbbbbbbbb bbbbbbbbbbbbbbbb cbbcbbbbbbbbbbbb bbcbcbcbbbbcbcbc'\n",
      " 'bcbcbbcbbcbbccbc bbbbbbbbbbbbbbbb bbbbbbcbbbbbbbcb bcbcbccbbbcbcccb'\n",
      " 'bbbcbbcbbbbcccbb bbbbbbbbbbbbbbbb bcbbbbbbbbbbbbbb bbbcbcbbbbcbbbcb bcbbbcbbbbbbbbbb'\n",
      " 'ccbccccccccccccc cccccccccccccccc cccccbcccccccccc bccbcccccccccccc'\n",
      " 'ccbccccccccccccc cccccccccccccccc cccccbcccccccccc bccbcccccccccccc'\n",
      " 'ccccbcbbcccbcccb cccccccccccccccc cccccbcccccbcccc cccccbcbccccbccc'\n",
      " 'bbbbbcbbbbbcbbbb cccccccccccccccc ccccccbccccccbcc'\n",
      " 'cbcbbcccbccbcccc cbcbbbcbcbcbbbcc bcbccbcbcbbbcbcc bcbbcbbbbbcbbcbc bcbccbbbbcbcbbcc'\n",
      " 'cbcbccbcccbbcbbc bccbcccccbccbcbc cbccbbcbbcbbcbcc cbccccbcbccccccc'\n",
      " 'bbcbbcbbcbcbbbcc cccccccccccccccc ccbccbbccccbbccc'\n",
      " 'bcbbcbbbbbbbcbbb ccbccccccccccccc bccbccbcccccccbc cbcbcbccbcccccbc bbbcbbcbbcbcbbcc'\n",
      " 'bbbbbbbbbbcbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'cccccbccccbccccc cbcccbcccbcbcbcb bcccbbbcbcbcbccb bbcbcbcbbcbccbcb'\n",
      " 'bccbbbbccbcbcbbb cccccccccccccccc cbcccccccccccccc ccbcccccccbccccc'\n",
      " 'cccccccccccccccc'\n",
      " 'ccbbccbcbbccbbcb bbbbcbbbbbbbbbbb cbbbbcbcbbbbbbbb cbcbbcbbbbbbcbbb cbbccbbbbcbcbcbb'\n",
      " 'cbcbcbcbcbcbcbbb cbcbbcccbcbbcbcc bcccbccbccbccccb cbbbcbcbccbcccbb'\n",
      " 'bbbcbbbbbbbbbccc bbbbbbbbbbbbbbbb bbbbbbbbbcbcbbbb bbbbbbbcbbbbbbbb'\n",
      " 'ccccccaaacccaaca bbbbbbbbbbbbbbbb' 'bccbcccbccbcccbc bbbbbbbbbbbbbbbb'\n",
      " 'bcbbbcccbcbcbccb cccccccccccccccc ccccccccccccccbc cccccccccccccbbc cccbcbccccbccbcc'\n",
      " 'cbcbccbcbccbccbc cccccccccccccbcb bbcbbbbbcbccbcbb bbbbbbbbbbbbbbbb bbbcbbbbbcbbbbbb'\n",
      " 'bbbbcbbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bcccbccccccbcccc bbbbbbbbbbbbbbbb bbbbbbbbcbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bccccccbbbcbbbcb bbbbbbbbbbbbbbbb' 'bccbcccbccbcccbc bbbbbbbbbbbbbbbb'\n",
      " 'cccbccbccbcccbcc ccbbbcbcccbccbcc cbcbcccccccccbcb cccccccccccbcccc ccbccccbcccccbcc'\n",
      " 'ccccccccbccccccb cccccccccccccccc' 'cbbbbbcbcbbbcbcb bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccbcc cccccccccccccccc cbcccccbcbccccbc bccbcbbcbcbcbbcb bcccccccbccbbcbc'\n",
      " 'cccccccccccbcccc cccccccccccccccc' 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc'\n",
      " 'bcbcbbccbbccbbcc cccccccccccccccc' 'cccccccccccccccc' 'cccccccccccccccc'\n",
      " 'bbcbcbbbbbbbbbbc bbcbbbbbbbbbbbbb bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbcbbbbbbbc bbbbbbbbbbbbbbbb bbcbbbbbbbbbbbbb bbbbcbbbbbcbbbbb'\n",
      " 'bcbbcbbbcbbbcbbc bbbbbbbbbbbbbbbb cbcbcbcbcbbccbbb'\n",
      " 'cccccbccccccbccc cccccccccccccccc' 'ccccccbcccbccbcc cccccccccccccccc'\n",
      " 'bbbcbbbcbbbbbbbb bcbbcbbbcbbbbbcb ccbbbcbbbbbcbbcb cbbbbcbccbccbccb bcbbcbbcbbbccbbb'\n",
      " 'cccbcbbccbcccbcc ccccccccccbccccc ccbcccbccccbbccb cbbcbbcbbccccbbb cbcbbcbcbccbcbbc'\n",
      " 'cccccccccccccccc' 'bbcbbccbbccbcccb cccccccccccccccc ccccccccccbccccb'\n",
      " 'cccccbcbcccccccc cccccccccccccccc ccccbccbcccccccc cccccccccccccccc'\n",
      " 'cccbccbccbcccbcc cccccccccccccccc ccccccbccccccccc bcccccbccccbcbcc'\n",
      " 'bbbbcbbbbbcbbcbb bbbbbcbbcbbbbbbb cccbcbcbbbcbcbcb ccccbcccbcccbbcc cccccccccbcbcccb'\n",
      " 'bbbcbbbbbbbbbbbb bbbbbbbbbbbbbbbb bbbbbcbbbbbbbbbb'\n",
      " 'bbbbbbcbbcbbbcbb bbbbbbbbbbbbbbbb bbcbbbcbbbbbbbbb bbbbbbbbbbbcbbbb'\n",
      " 'cccbccccccbcccbc cccccccccccccccc bcccccbcccbccccc' 'cccccccccccccccc'\n",
      " 'bcbccbbcbcbcbbbb cccccccccccccccc'\n",
      " 'cbbbbbbcbbbbbbbb bbbbbbbbbcbbbbbb bbcccbcbbcbbcbbb ccccccbccccccccb'\n",
      " 'cccccccbcccccccc cccccccccccccccc ccccccccccbccccb ccbccccbcccbcccb ccbccccbccccccbc'\n",
      " 'bcbbbcbbbbbbbbcb bbbbbbbbbbbbbbbb bbbbbbbbbbbbcbbb bbcbbbbbcbbbbccb cbbbcbcbbbccbcbb'\n",
      " 'bbbbbbbbbbbbbbbb bccccbccccccccbc'\n",
      " 'bcbbbcbbbbbbbbcb bbbbbbbbbbbbbbbb bbbbbbbbbbbbcbbb bbcbbbbbcbbbbccb cbbbcbcbbbccbcbb'\n",
      " 'ccccbcccbccbbccc cbbbbbbbbbbbbcbb bbbbbbcbbbcbcbcb bcbbbcbcbcccbcbb bbbccbbbbbbcbbbb'\n",
      " 'bbbbbcbbbbbbbbbb bbbbbbbbbbbbbbbb bbbbbbbbcbbbbbbb'\n",
      " 'bbbcbbbbbbbbbbbb bbbbbbbbbbbbbbbb bbbbbbbbbcbbbbbb'\n",
      " 'bbcccbccbcbccbcc bccccbcbccbcccbc cccbcccbcbcbbcbb ccbccbcbcbbcbbbc'\n",
      " 'bbbcbbbcbbcbbccb bbcbbcbbcbbbbbbb bbbbcbcbbcbcbcbb bcbcbbbbbbbbbbbb'\n",
      " 'cbccbbbbcbcbbbbc ccbcbcbcbbcbbbcc bccbccbcbcbbbccc bbcbbcbccbcccbbc'\n",
      " 'cbccbcbcbccbcbcc cccccccccccccccc ccccccbccccccccc'\n",
      " 'cbcbcbcbcbcbccbc cbccccbccccccccc bccbcccbccbccbcb bbcbbbcbcbcbcbbc'\n",
      " 'bbbbbbcbcbbbbbbb bbbbbbbbbbbbbbbb bbbbbbbbbbbcbbcb bccbbcbcbbbbccbb'\n",
      " 'cccccccccccccccc cccccccccccbcbcc ccccccccccccbccc cbbbbccbbbbcbbcb'\n",
      " 'cbcccbbcccbbccbc bcbbbbbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc ccccccccccbccccc'\n",
      " 'cccbbccbbcbccbbb cbcbbbcbbbbbbbbb bbbcbbbbbbbbbbbb cbcbcbbcbbbbcbcb bbbcbbbbcbbbbccb'\n",
      " 'bbcbbbbccbbbcbbb bbbbbbbbbbbbbbbb bbcbbbbcbbbcbcbb bcbbbcbbcbbccbbb'\n",
      " 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbcbbcbbbbbbb bbcbbbbcbbcbbbbb cbbbbbbbbcbbbbbb cbcbccbbbcbbcbbc'\n",
      " 'ccccccbcccbccccc cccccccbcccccccc cccbccccccccbccc bcbbccbbcbcbbbcb'\n",
      " 'bbbcbbbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bbcbcbbcbcbbbbbb bbbbbbbbbcbbbbbb bbbbbbbbbbbbbbbb cbcbbbbbbbbbbbbb bbbbcbbbbbcbbbcb'\n",
      " 'bcccbbcbbcbcbbbb cccccbcbccbcccbc ccbcccbccbcbbcbc cbbcbbcbbcbcbbbc cbcccbbccbccbccb'\n",
      " 'ccbcccccbcbbcccb cccccccccccccccc' 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc' 'cccccccccccccccc bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb bccccbcccccbccbc'\n",
      " 'bbbbbbbbbbbbbbbb bbcbbbcbbbbbbbcc' 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb ccbccccbccbcbccc cccccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc cccccccccccccccb bbcbbbbbbbbbbbbb bcbbbbbbbbbbbbcb'\n",
      " 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb bbbbbcccbbcbbbbc bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc ccccccccbcccccbc' 'bbbbbbbbbbbbbbbb bbbbbbbbbbbbbcbb'\n",
      " 'bbbbbbbbbbbbbbbb bcbccccccccccccc cccccccccccccccc'\n",
      " 'cccccccccccccccb bbbcbbbbcbbbbbbb bbccccccccccbccc cccccbbbbcbbbccc ccccbcbccccccccc'\n",
      " 'cccccccccccccccc cbbbbbbbbbbbbbbb bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc cccccccbcccbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'cccccbcbbbbbbbbb bbbbccbbbbcccccc bbcbbbbbbcccccbc bbbbcccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb bbbbbbbbbbbbbbbc cccccccccccccbcc'\n",
      " 'cccccccccccccccc ccccccccbccccccc cccccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb'\n",
      " 'cbcbcbbccccbcbbc cccccccccccccccc bccccccccccccccc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb ccbccccbbcbcbccb cccccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc ccccbccccccccccc bbcccbbcbbcbbbcb'\n",
      " 'bbbbbbbbbbbbbbbb bcbbbbbbbbbcbbbb'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc cccccccccccccccb bbcbbbbbbbbbbbbb bcbbbbbbbbbbbbcb'\n",
      " 'ccccccccbccccccc bbbbcbbbbbbbbbbb bbbbbbbbbbbbbbbb' 'cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbbbbbbbbc ccccccbccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbcccbbcbbbbc bccccbbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'cbbcbbbbcbcbbbbb cbbbbbbbbbcbbbbc bcbcbbccccbbbbcc ccccccbccccbbccc bccbcbccbbcccccc'\n",
      " 'bbbbbbbbbbbbbbbb bcbbbbbbcbbbbbbb ccccbcbcbbcbcccc'\n",
      " 'cccccccccccccccc ccccccccbcccccbc' 'cccccccccbbccccc bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbbbbbbcbb'\n",
      " 'cccccccccccccccb bbbcbbbbcbbbbbbb bbbcccccccccbccc cccccbbbbcbbbccc ccccbcbccccccccc'\n",
      " 'cccccccccccccccc cbbbbbbbbbbbbbbb bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc cccccccbcccbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'cccccbcbbbbbbbbb bbbbccbbbbcccccc bbcbbbbbbcccccbc bbbbcccccccccccc'\n",
      " 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb cccccccccccccccc' 'cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc bcbccbbbbbcbcbcb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbcbbcbbbbbbb bbbbbbbbbbbbbbbb cbcccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbbbbbbcbb bcbccbbccccccbcc cccccccccccccccc'\n",
      " 'cccccccccccccccc' 'cccbcccbbccbcccb cccbbbbbcbbbbbbc bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb cbccbcccbbccbccc ccccccbccccccccc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb'\n",
      " 'cccccccbccbcccbc cccccccccccccccc ccccccccbccccccc cbbcbbccbbbbcbcb bcbccbcbcbbcbcbc'\n",
      " 'cbbcbcbcbbbbbbbb cbbbbbbbbbbccbbb bccbcbccbcbcbbcb cccccbccccbccccc cccccbcccccbccbc'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb bbccbcbbcbbcbcbb bbbbbbbbbbbbbbbc'\n",
      " 'bbcbbbbbbbccbbcb bbbbbbbbbbbbbbbb cbccbbccbcbbccbc bbbbbbbbbbbbbbbb cccbcbccbcbcbbcc'\n",
      " 'cccccccccccccccc cbbbcbcbcbcbccbc bbbbbbbbbbbbbbbb bbbbbbbbcbbcbbbb bcbbbcbcbbbbbcbb'\n",
      " 'cccbcccccccccccc bbbbbbbbbbcbbbbb cbbbbcbcbbbbcbbc bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb cccccccccccccccc cbbcbccbcbcbccbc'\n",
      " 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc bbbbbbbbbbbbbbbb bbbbbbbbbcbbbbbb'\n",
      " 'bcbccccccbcccbcc bbbbbbbbbbbbbbbb cbccbbccbcbcbcbc bccccccccccccccc'\n",
      " 'cccccccbcccccccc bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb'\n",
      " 'cbccccbccbcccccc bbbbbbbbbbbbbbbb bbbbbbbbbbcbbbbb bbbbbbbbbbbbbbbb bbbbbbbbbcbbbbbb'\n",
      " 'cccccccccccccccc bbbbbcbbbbbbbbbb bbbbbbbbbbbbbbbb' 'cccccccccccccccc'\n",
      " 'cbcccbccbccccccb ccccccccccbccbcc cccccccccccccccc cccccbccbccbcccc cbccbccbcccccccb'\n",
      " 'cccccccccccccccc ccbcbcbcbbccccbc'\n",
      " 'cbcbccccccbccbcc bccccccccccccccc ccccccccbccbcccc cbcbcbbbcbcbbccb'\n",
      " 'cbccccccccbccccc cccccccccccccccc bccccccccccccccc cbccbccccbccccbb cccbcbcccccccbbc'\n",
      " 'cbcbbbbbbbbbbcbb bbbbccccbcbbbbbb bcccbbbbbbbbbbbb cbccccbbcbbcbcbc cccccccccccccccc'\n",
      " 'bbbbbbbbbbcbcbbb bbcbcbcccccbbbcb bbbbbcbcbbbbbcbb bcbcbcbbcbbbcbbb bcbcccbcccbccbcc'\n",
      " 'bbbbbbbcbbcbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bcccbcbcccccccbc bcccccccccccccbc ccccbcccccbcbbbc cccccbcbbcbbbbcb bcccbcbcbbbccccb'\n",
      " 'cccccccbccccbcbc ccccccccccbccccc ccccbcbccccccccc cccccbccbcbccccc'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc ccccccccbcccccbc'\n",
      " 'ccccbccccbcccccc bccccbbccbcccbcc bcbcccbccbcbbccb ccbcbccbbbccbcbb'\n",
      " 'bbbbbbbbbbbbbbbb ccccbccbcbcccbcc ccccbcbcccccbccc ccbccbccbcbccccc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb bccccccccccccccc cccccccccccccccc cccccbccccbbcbcb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbcbcbbbbb bbbbbbcbbcbbbcbb bcbbbbbbbbbbbbbb'\n",
      " 'bbbbccbbbbbbbbbb bbbbbbbbbbbbbbbb' 'bbbbbbbbbcbbbcbb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb'\n",
      " 'bbcbbbbbbbbbbcbb bbbbbcccbbbbbbbb bcccccbbbbbbbbbb ccbbbbbbbbbbbbbb ccccccccbcbccccc'\n",
      " 'cbbbbbbbbbbbbbcb bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccbcc bccccccccccccbcc cccccccccccccccc cbcccbbccccbcbbc bccbbcbbcbcbbbbb'\n",
      " 'bbcbccccbbccbccc bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'bcbbbbbbbbbbbbbb bbbbbbbbbbbbbbbb' 'bbbbcbcbbbbcbbbb bbbbbbbbbbbbbbbb'\n",
      " 'ccccbcbccccbcccc cccccccccccccccc cccbcccccccccccc bbcbcbbccbbcbcbc'\n",
      " 'bbbbbbbbbbbbbbbb bbcbbbbbbcbbbbbb' 'cbbbbbbbcbcbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbcbbbbbbb bbbbbbbbbbbbbbbb bbbcbbbbbcbbbcbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'cbcbbcbcbcbcbcbc bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbcbbcbcbbbb bbbbbbbbbbbbbbbb bbbbbcbbbbbbbbbb'\n",
      " 'cccbcccccbcbccbb cccccccccccccccc ccccccbcccccbccc cccccccccbcccccc'\n",
      " 'cbccbcbcccbccbbc bbbbbbbbbbbbbbcb bbbbbbbbbbbbbbbb bbbbbbbbbbcbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bccccccccccccccc cccccccccccccccc cccccbccccbbcbcb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbcbcbbbbb bbbbbbcbbcbbbcbb bcbbbbbbbbbbbbbb'\n",
      " 'bbbbccbbbbbbbbbb bbbbbbbbbbbbbbbb' 'bbbbbbbbbcbbbcbb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb'\n",
      " 'bbcbbbbbbbbbbcbb bbbbbcccbbbbbbbb bcccccbbbbbbbbbb ccbbbbbbbbbbbbbb ccccccccbcbccccc'\n",
      " 'cbccccbcccbccbcb cccccccccccccccc ccccbccccccccccc'\n",
      " 'cccccccccccccccc cccbbbbbbbbbbbbb bbbbbbbbbcbbbbbb bbcbbbbbcbbbcbbb'\n",
      " 'bbbbbbbbbbcbbbbb bbbbbbbbbbbbbbbb bbbbcbbbbbbbbbbb cccbbcbccbcbcbbc cccccccbcccbcccb'\n",
      " 'bccbcbccccccbccc cccccccccccccccc'\n",
      " 'bbcbbbcbbcbbcbbb ccccccbccbcbcccc bbbbccbbccbbcbcb ccbbccbbcbcbccbc bcbbcbcbbbcbbbbc'\n",
      " 'ccbccccccccccccc bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbcbb bbbbbbbbbbbbbbbb cbbbbbbbbbbbbbbb'\n",
      " 'cbbcccccbcbccbcc cbbbcbcccccccbbb ccbcbcccccbcbccb cccccbcbbcbcbccb bbccbbbcbcbccbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbccbcbbcbbbbbbb bcbcbcbcbcbbcbbb cbbcbbbbcbbcbbcb cccccbcccbcbcbcc'\n",
      " 'cccccccccccccbcc bbbbbbbbbbbbbbbb bbbbbbbcbbbbbbbb'\n",
      " 'cbccbcbbcccbbccb bbbbbbbbcbcbbbbb bbbbbbbbbbbbbbbb bcbbbbbbcbcbbcbb'\n",
      " 'bcbcbccbbbbcbbbb cccccccccccccccc'\n",
      " 'bccccccbccbcccbb bbbbbbbbbbcbbbbb bbbbbbbbbbbbbbbb bbbbccbbbbbbbbbb'\n",
      " 'ccccccccccccccbc bbbbbbbbbbbbbbbb'\n",
      " 'bcbcbcbccbcbcbbb cccccbcbbcbcbcbc ccbccccccbcbcbcc cccccccccbcccccc cccbcccbcbcccccb'\n",
      " 'bbcbcbbbbbbbbbbb bbbbbbbbbbbbbbbb bbbbbccbbbbcbbbb bbcccbbcbccbcbcb'\n",
      " 'cbcbbccbbbcbcbcc bbbbbbbbbbbbbbbb cbbbbbbbbbbbbcbc bbbcbcbbbcbbbbbc cbccbcbcbcbcbccb'\n",
      " 'cccbccbccccccbcc cccccccccccccccc' 'cccccccccccccccc'\n",
      " 'bbbcbbbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'cbbcbbbbccbccbcb cbbbbbbbbbcbbbbb bccbcbbbcbbbbbbb cccccccccccccccc'\n",
      " 'ccccccccbccccccc cbbcbbbbbbcbbbbb cbcbcccbccbcbcbb bbbbbbbbbbbbbbbb bbbbbbbcbcbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbbcbbbbbb cbcccbccbcccbbcb cccccccccbccccbb'\n",
      " 'cccccccccccccccc' 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb bbbbbbcbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc' 'bbbbbbbcbbcbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'cbbbbbbbbcbbcbcb bbbbbbbbbbbbbbbb'\n",
      " 'ccbccbbccccbcbcb ccbbbcbbbcbbbbbb bbbbbbbbbbbbbbbb bbccbbccccbbcbcb ccbcbccbcccbcccb'\n",
      " 'cbbcbbbbbbbbbcbb bcbcbbbbbbbcbccb cccbccbccbbccbcc cccccccccccccccc bcbbbcbbbbbcbbcb'\n",
      " 'cbbbcbbbbbbcbbcb bbcbbbbbbbbbbbbb bbbbbbbbbbbbbbbb bbbbbbbbcbbbbbbb bcbccbcbbbcbcbcb'\n",
      " 'cccccccccccccccc cbccccccccccbccb ccccccbcccccccbc' 'cccccccccccccccc'\n",
      " 'bbbbbbbbbbcbbbbb cccccccccccccccc ccbcccbcbccbcbbc' 'bbbbbbbbbbbbbbbb'\n",
      " 'cbbcbbbbbbbbbbcb bbbbbbbbbbbbbbbb bbbbcbbbbbbbbbbb'\n",
      " 'cccccccccccccccc bbbbbcbbbbbbbcbb bbbbbbbbbbcbbbbb'\n",
      " 'ccccccccccbccccc cccccccccccccccc cccccccccccbcccc'\n",
      " 'bbbbbbbbbbbcbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bcccbcccccccbccc cccccccccccccccb ccbcccccbccccccc ccccbbcccbccccbc bcccccccccccbccc'\n",
      " 'bbcbbbbbbbbbbbbb cccccccccccccccc cccccccccccccbcc bccbcbbccbcbbccb cccccccbccccccbc'\n",
      " 'bbbbbbbbbbbbbbbb bbbbcbbbbbbbbbcb'\n",
      " 'cccccccbccbcbccc ccbbcccbccbccbbc cccbbcccbbbbbbbc cccbcbcbcbbbbbcc ccbccbcbbbcbcbcc'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc ccbccbbcbbcbccbc'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbcbcbcbbbcbb' 'bbbbbbbbbbbbbbbb cbbbbbbbbcbbcbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbcbbbbbbb' 'bbbbbbbbbbbbbbbb bbbbbbbbbbcbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb' 'bbcbbcbcbbbbbbcb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bccccccbcccccccc bbccbbcbbcbcbbbc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbc bbbbbbbcbcbbbbbb cccbccccbcccbccb bbccbcbcbccbbcbb'\n",
      " 'cccccccccccccccc cccccccccccccbcc' 'cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb cccccccbcccccccc bbbbbbbbbbbbbbcb cbbbbbbbbcbcbcbc'\n",
      " 'cbbbbbccbccbbcbc cbccbccbbbbcccbb ccbbbccccbcccbbb'\n",
      " 'bbbcbbbccbbcbbbb cccccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'bcbbbcbbbbcbbbcb bbbbbbbbbcbbbccb bbbbbbbbbbbbcbbb bbcbbbbbbccbcbbb bbbcccbbbccbbbbc'\n",
      " 'bccbcbbbccbcbbbc bbcbbbccbbcbbbbc bcccbbccccbcbcbb cbbcbbcbbcccbcbb'\n",
      " 'cccccccccccccccc'\n",
      " 'bbbbbbbbcbcbbbbc cccccbcccccccccc cccccccccccccccc cccccbcccccbcbcc'\n",
      " 'cbccbcbcbbcbbbcc bbccbbcbbcbbcbbc bcbccbbcccbbbbcb cbccbcbccccbcccc'\n",
      " 'bcbbcbbbbcbbccbc ccccccbccccccccb'\n",
      " 'bccbbccbbcbcbbbc cbbbbbbbbbbcbbbb bbbbbbbbbcbbbcbc bbbcbbcbbcbbbbbc'\n",
      " 'bbbbbbbbbbbbbbbb bbbbcbcbcbcbcbbc bbbbcbbcbbbcbbbb'\n",
      " 'cbcbcbcccbbbccbb cbcbccccccccbbcb cccccccccccccccc ccccbcccbccbccbc bccccccbcccccbcc'\n",
      " 'bbbbbbbbcbcbbbbc cccccbcccccccccc cccccccccccccccc cccccbcccccbcbcc'\n",
      " 'bcccbccbcbbccbcc bcccbccbbcbcbbbb bcbccbcbcbcbcccb bcbcbcbbcbcbccbc'\n",
      " 'cccccccccccccccc cccbbbccccbccbbb bbbcccbcbbcbbbbb cbccbbbbcbbbbbbb cccccbcccbcbcbcb'\n",
      " 'bbbbbbbbbbbbbbbb'\n",
      " 'cbcbbbbbbbbbcbcb bbbcbbbbbbbbbcbb bbbbbbbbbcbbcbcb bbbbbbbbbbcbbcbb ccbbcbcbbbccbbcb'\n",
      " 'bbbbbbbbbbcbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'ccccccccccccbccb bbbbbbbbbbbbbbbb bbbcbbcbbbbbbbbb'\n",
      " 'ccbccccccccccccc cccccccccccccccc ccbccccbcbcccbcc ccbbbccbccbcbccc cbbbbbccbbcbbbbb'\n",
      " 'cccccccbcccbcccb cccccccccccccccc bbccbbcbbccbcbcb bbbbbbbbcbcbbcbc bbbbcbbbbbcbbbcb'\n",
      " 'bbccbcbbcbcbbcbc cccccccccccccccc ccccbccccccccccc'\n",
      " 'ccbcccccccbccbbb cbcccccccccccccc cccccbcbcbcccccc'\n",
      " 'ccbccccccccccccc cccccccccccccccc ccbccccbcbcccbcc ccbbbccbccbcbccc cbbbbbccbbcbbbbb'\n",
      " 'cbcbbcbbbbcbbbbb bbbbbbbbbbbbbbbb bbccbbbbbcbcbcbb'\n",
      " 'ccbbccbccbbccbcc cccccccccccccccc'\n",
      " 'bbcbcccbbcbccbcb bbbcbbbbbbbbbbbb bbbbbbbbbbbbbbbb bbbbbbbbbbbbcbbb cbcbcbbbcccbbbbc'\n",
      " 'cccccbcbcbcccccb bbbbbbbbbbbbbbbb bbbbbbbbcbbbbbcb'\n",
      " 'cbccbcbcbcbcbccc bbbbbbbbbbbbbbbb bbcbbbbbbbbbbcbb bbbbbcbbbbcbcbcb'\n",
      " 'ccbccccccccbcbcc cbcbbbbbcbbbcbbb bcbbbbbbbbbbbbbb cbbbbbbbbbbbcbbc cbbcbbbbbcbbcbcb'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc cccbcccccbcbbccb'\n",
      " 'bbbbbbbbbbbbbbbb bbbcccbbbbbbbbbb ccccccbbbbbbbbbb cccbbbbcbbbbcbbb'\n",
      " 'bcbbbbbbbbbcbcbb cccccccbcccbcccc cbbcbbbbbbbbbbbc bcbbbcbbcbbcbcbb'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb bbbbbbbbbcbbbbbb'\n",
      " 'cbbbbbbcbbbbbbbb ccccccccccccccbc cccccccccccccccc cbbbcbbcbcbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbcbbbbbbbbcbc bbcbbccbcbcbbbcb'\n",
      " 'bcbbbbbbbcbbbbbc bbbbbbbcbbbbbbbb bbbbbbbbccbbbbbb bbbbbbbbbbbbbbbb cbcbbcbbbbbbbbbb'\n",
      " 'bcbccccccccccbcc cccccccccccccccc cbcccccccccccccc bcccbccccccccbcc'\n",
      " 'bbbbbbbbbbbbbbbb' 'cbbcbccbcbbbcccb cccccccccccccccc'\n",
      " 'cbbccbbbcbbbbcbc bbcbccbcccccbccc ccbccccbccccccbc cbccccbcbccccbbc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc bbbbbbbbbbbbbbbb bbcbbbbcbcbbbbbb'\n",
      " 'cccccccccccccccc cccccbcbccbccbbc' 'cccccccccccccccc bbbbbbbbbbbbbbbb'\n",
      " 'bbbbcccbcbcbbbbb bbbbbbbbbbbbbbbb bbbbbbbbbcbbbbbb'\n",
      " 'bcbbbbcbbcbccbbb bbbbbbbbbbbbbbbb'\n",
      " 'cbcbccbcbbbcccbb bbbbbbbbbbbbbbbb bbbbbbbbbbbbcbbb cbccbbcbbbcbcbcb bbbbbbbbbbbbbbbb'\n",
      " 'ccbbcbcbbcbcbccb cccbccccbccccccc cccccbcbccccccbc bccbccccbccbcbbc bbcbbcbcccbcbccb'\n",
      " 'bbbcbbbbbcbcbbbb bbbbbbbbbbbbbbbb' 'bcbcbccbbcbccbcc bbbbbbbbbbbbbbbb'\n",
      " 'ccccbccccccccccc cccccccccccccccc'\n",
      " 'cbccccccbbcccccb cccccccccccccccc ccccccccccbccccc cccccccccccccccc bccbcccbcbbccccc'\n",
      " 'ccccbccbbbbcbbcb cccccccccccccccc cccccccccccccbcc'\n",
      " 'cccccccccccccccc cccccccccccccbcc' 'cccccccccccccccc' 'cccccccccccccccc'\n",
      " 'cccccccccccccccc' 'cccccccccccccccc cccccccccccccbcb' 'cccccccccccccccc'\n",
      " 'cccccccccccccccc' 'cccccccccccccccc' 'cccccccccccccccc'\n",
      " 'cccccccccccccccc ccccbccccccccccc' 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc'\n",
      " 'cbccccccccccccbc cccccccccccccccc'\n",
      " 'bcbcbcbccbcbccbc cccccccccccccccc cccbcccccccbcccc cccccccccccccccc bbcbcbcbcbbccbbc'\n",
      " 'ccccccccccbcccbc cccccccccccccccc ccccccbccccccccc'\n",
      " 'bcbbbccbcbbcbcbc bbbbbbbbbbbbbbbb bbbbbbbbbcbbbbbb ccccccccccbcbcbc'\n",
      " 'cccccccccccccccc ccccccbccccccccc'\n",
      " 'bbbbbbbbbbbbbcbb cccccccccccccccc cbcccccccccccccc bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc'\n",
      " 'cbcccbccbcbccbcc ccccbccccccbccbc bbbbcbcbbbcbbcbb ccccccbcccbccccc cccbcbccccbccccb'\n",
      " 'bbbbbbbbbbbcbbbb bbbbbbbbbbbbbbbb bbcbbbbbbbbbbbbb'\n",
      " 'cbbccbcbcbcbbbcb cccccccccccccccc'\n",
      " 'ccccccccccccccbc bbbbbbbbbcbbbcbb bbbbbbbbbbbbbbbb bbcbbbbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bbcbcbbcccbbcccb bbbbcbbbbcbccbcb ccbbbcbcbbcbbcbb cbbcbbbbccbbbcbb'\n",
      " 'cbcbcccccbcbbcbb cccccccccccccccc cccccccccccccccb cbccccbccbcbccbc'\n",
      " 'cbbbcbcbbbbbcbbb bbbbbbbbbbbbbbbb bbbbbbbbbbbbbcbb bbbbbbbbbbbbbbbb bbbcbcbcbbbbbbcb'\n",
      " 'cbbbbbbcbbbbbbbb bbbbbbbbbbbbbbbb cbbcbbbbcbbbbbbb'\n",
      " 'bcbbccbcbcbcccbb cccccccccccccccc cbcbccccbccbcbcb cbcbcccbcccbcccc'\n",
      " 'cccccbcbcccccccc cccccccccccbcccc cbcccbcccbbccbcb ccbbbcbbbccbbcbc'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbbbccbbbb bbbbbbbbbcbbbbbb bbbbccccbbbbbbbb cbcccccccbcbcbcb'\n",
      " 'bbbbbbbbbbbbbbbb bbcbbbbbbcccbbcc bccccccccccbcccc cbcbccbccccccccc'\n",
      " 'bbbbbcbbbcbcbbcb bbbbbbbbbbbbbbbb bbbbcbbcbbbbbbbb'\n",
      " 'bcccccbbbbbbbbbb bbbbbbbbbbcbbccb bbbbbbbbccbbccbb bbbbbcbbbbbccbbb bbbbbbccccbbbbbb'\n",
      " 'bbbbbbcbbbbbbbbb cccccccccccccccc'\n",
      " 'cbcccccccbcccccc cccccccccccccccc ccccccccccbccccc'\n",
      " 'ccccccccccccccbc cbbcccccbcbccccc ccccbccbcccccccc cccccccccccccccc'\n",
      " 'bbbbcbcbbcccbbcb ccccccccccccbccc ccbcccbcbccbccbc ccbccbcccbcccccc bcbbcbbcbcbcbccb'\n",
      " 'bcbcbcbbccbbcbcb cccccbbccbccbccb cccccccccccccccc bcbcccbccccccccc bccbccccccbccccb'\n",
      " 'bcccccbccbbccccc cccccccccccccccc cbbcccbccbcccccc'\n",
      " 'bcbbbbbbcbbccbbb cccccccccccccccc'\n",
      " 'cbcbbcbccbbbbbcb bbbbbbbbbbbbbbbb bbbbbbbbbbbbbbbc' 'cccccccccccccccc'\n",
      " 'cbbccbcbcbbbcbcb bbbbbbbbbbbbbcbb bbbcbbcbbbbbbbbb bccbbbcbbbccbbcb bbcbcbbcbccbcccb'\n",
      " 'cccccccccccccccc cccbccccccccbccb' 'bcbbbbbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb cbcbcbccbccccbcc'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbcbbbbbbb ccbccbccccbccccc'\n",
      " 'cbbbbbbbbcbcbcbb bbbbbbbbbbbbbbbb cccccccbcbccbcbc'\n",
      " 'ccbccccccccccccc bbccbbcbcbbbcbbb cbbcccccbcbcbccb ccbcbbcbccbcbbcb ccbcbbcccbcbcccb'\n",
      " 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'ccbccccccbcccccc bbbbbbcbbbbbbbbc bcbbbbbbbcbbbcbb bbcbcccbbcbccbcc bbcbcbbcbcbbcbbc'\n",
      " 'bccccccccccbccbc bcbccbbccbcccccb cbbbcccbcbbcccbb cccbccbcbcbccbcb bcccbbcccccbccbc'\n",
      " 'bbcbcbccbbbbcbbc cbbbbbbbbcbbbbbb bccbbcbbcbcbbbcc cbbbcbbbbbbbcbcb'\n",
      " 'bbcbcbccbbbbcbbc cbbbbbbbbcbbbbbb bccbbcbbcbcbbbcc cbbbcbbbbbbbcbcb'\n",
      " 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbcbcbbbbbbcbb bbbbbbbbbbbbbbbb bbcbbbbbbbbbbbbb ccbcccbccccbcccc bbcbcbbbbccccccb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbbcbbbcbc'\n",
      " 'bcbcbbcbbbbbbbcb bccccccccccccccc cccccccccccccccc'\n",
      " 'bbbbbbbbbcbbbbbb bbbbbbbbbbbbbbbb' 'bbcbcbcbcbcbbcbc cccccccccccccccc'\n",
      " 'cccccbcbccccccbc cccccccccccccccc cbccccccbcbccccc'\n",
      " 'bcbcbbbbbbbcbbcb cccbcbbccbbcbccc cccbcccccbcccccb cccccbccbcccbcbc'\n",
      " 'cccbccbcccbccbcb cccccccccccccccc' 'bcbbbcbbbcbbbcbc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb bbcbbbbbbbbbbcbb bbbbbbcbbcbbcbbb bbcbbbbccbbcbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbcbbbbbbcb' 'bbbbbbbbbbbbbbbb bbbbbcbbbbbbbbbb'\n",
      " 'bbcbbcbbbcbbcbbc bcbcbcbccbcbbbbb bbcbcccbbcbcbcbc cccbccbccccccccc bbcbbcbcbcbcbcbb'\n",
      " 'bbbbbbbbcbbbbbbb bbbbbbbbbbbbbbbb' 'cccccccccccccccc'\n",
      " 'bccccbcccbccbccc cccccccccccccccc' 'bbbbbbbbbbbbbbbb cccccccccccccccc'\n",
      " 'bcbcbcbbcbcbccbc bbbbbbbbbbbbbbbb cccccccccccccccc' 'cccccccccccccccc'\n",
      " 'cccccccccbccbccc cccccccccccccccc ccbccccccccccccc ccccbcccbcbccccc bbbbbbbbbbbcccbc'\n",
      " 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb cccccccccccccccc'\n",
      " 'cccccccccccccbcc ccccccccccbbbbbb ccccccccbbbbbbbb ccccbcbcbcbcbcbc cbccbcccbccccbcc'\n",
      " 'bbbbbcbbcbbbbbbc bbbbbbbbbbbbbbbc bbbbbbbbbbbbbbbb bcbbbbbbbbbcbbcb cbbcbbccbbbbccbc'\n",
      " 'cccccccccccccccc'\n",
      " 'ccccccbbccbbcccc bccbcbbbcbccbbcb ccbcbcbccccbbccb cbcbcbccbcbcccbb'\n",
      " 'bbbbbbbbbbcbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccbcc cbccbcccccbcbccc bbbccbccbbbbcccc bccccccccbcccccc bbbbcbbbcbbbbcbb'\n",
      " 'cccccccccccccccc cccccbcccccccccb'\n",
      " 'cccccccccccccccc cbccbcbbbcbcbbbb bccbbbccbcbcccbc ccccbccccbcbcccc bcbbcbbccccbcccb'\n",
      " 'bbcbccbbbcbbcbbc cccccccccccccccc bcccbcbccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb' 'bbccbcbbcbcccccb bbbbbbbbbbbbbbbb' 'cccccccccccccccc'\n",
      " 'bbbbbbbccbbcbcbc bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc bbbcbcccbcbcbbcc' 'bbbbbbbbbbbbbbbb'\n",
      " 'cccbcccbccccccbc cccccccccccccccc cccccccccccccccb ccbcccbcbccccbcb'\n",
      " 'cccccccccccccccc'\n",
      " 'bbbbbbbccccccccc cccbccccccccbccc cbcbbcbbbcbbcbbc cccccccccccccccc bbcbbbbbbcbcbcbb'\n",
      " 'cccccccccccccccc cbcbbcbcbccbbbcb ccccccccbcccbccc ccbcbcbcbcbccccb bbbcbbbccbbcbcbb'\n",
      " 'ccbcccccbccccbcc cccccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb ccbcbbbcbcbccccb bbcbbccbbbbcbcbb bbcbbbcbbcbbbbbb bbbcbbbbcbbcbcbb'\n",
      " 'bbbbbbbbcbbbbbcb bbbbbbbbbbbbbbbb bbcbcbbbbbbbcbbb cbcccbccbcbccbcb cbcccccbcccbcccc'\n",
      " 'cccccccccccccccc bccccbcccccccccc bcbbbbbbbbbbbbbb bbcbbbcbbbbbbbbb'\n",
      " 'cccccccccbccbbcc cccccccccccccccc bbcccccbcbbccccb cbcbcbcbbcbbcbbb bbbbbbbbcbbbcbbb'\n",
      " 'bbbbbbbbbbbbcbbb cccbcbccbcbccbcc ccbccccccccccccc'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc' 'bbbbbbbbbbbbbbbb bbbbcbcbbcbbbbbc'\n",
      " 'cccccccccccccccc cbcbbcbcbbcbbbcb' 'bbbbbbbbbbbbbbbb bbbbbbbbbbbbbbcb'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc bccbbbcbbbbbbbbb bbbbbbbcbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'cccbccbbbbbccbbb cccccccccccccccc cccccccccccccbcc'\n",
      " 'bbbbbbbbbbbbbbbb cccccccccccccccc' 'ccbbccbcbcccccbc cccccccccccccccc'\n",
      " 'cccccccccccccccc' 'cbbbbbcbbbbbbbbb cccccbbbbbbbbbbb cccccccccccccccc'\n",
      " 'cccccccccccccccc' 'ccbcbbcbccccbccc bbbbbbbbbbbbbbbb'\n",
      " 'bcbcbbcbbbbbbbbb bcbbbbbbbcbbbbbb bbbbcccccbbbbbbb bcccbbbbbbbbbbbb bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bcbbbbbccccccccc bbbbbbcbbcccbbbb bcbcccccccccbcbc ccccbcccbcbcbbcc'\n",
      " 'ccccbbbbbcccbccb cccbccccccccccbc ccbcccbcbcbcccbc cbbcbccbccbcbbcb cccbbbcccbbcbccb'\n",
      " 'ccbcbccbbcccccbc cccbbccbccbcccbb bcccbbccbcbcccbb bbcbbbcbbbbcbbbb cbbccbcccbbbbbbb'\n",
      " 'cbbcbbbbbccbcccb bbcbbccbcbbcbcbb bcbcbbbcbbcbcbbb cbbcbcccbcbbbccb'\n",
      " 'cccbcbbcbccbbccc cbccccbcbccbbccc ccbcccbcccbbcccc cccccccbbccccccc'\n",
      " 'bcbbccccccccccbb cbccccbccccbccbc ccccbccbcbbccbcc ccbbbccccbbbccbc'\n",
      " 'cbbbcbbcbbbcbbbb cccbcbbccbccccbc bcbccbbcccbcbccc cccbbbbcbbbbcccb'\n",
      " 'ccccccccccccbccc ccccccbccccccbcb ccccccccccccbccb ccccccccccbbccbc ccbcbcbcccccbbbc'\n",
      " 'bbcccbbbbccbbccb cccccccccccccccc bccccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbbbbbcbbb' 'cbcbccccbccccccc cccccccccccccccc'\n",
      " 'cccccccccccccccc'\n",
      " 'cccccccccccccccc cccccccccccccbcb cccccccccccccccc ccccccccccbccccb ccbcbbcbcbcbbcbb'\n",
      " 'bbbbbbbbbbbbbbbb' 'bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccccccccc bbbbbbbcccbcbbbb bbbbcccbbccbbbbb ccbbbbbcbbbbbbbb cbcbcccbcbcbcccc'\n",
      " 'ccccccbccccccccc cbbcbbcbbbccbbbb cccccccccccccccc ccccccccbccccbcc'\n",
      " 'cccccbbccccccccc cccccccccccccccc' 'cccccccccccccccc' 'bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb bbbbbbbbbbcbbbbb bbccbbbcbbcbcccc bbbbbcbbcbbcbcbc'\n",
      " 'cbbbbbbbbbbbbbbb cbcbbbbbbbbbbbbb cbbcbbcccbccbccb bccbcbbcbcccccbc'\n",
      " 'cccccccccccccccc' 'bcbbbbbbbbcbbcbb bbbbbbbbbbbbbbbb'\n",
      " 'cccccccccbcccccc bbbbbbbbbbbbbbbb' 'cccccccccccccccc bbbbbbbbbbbbbbbb'\n",
      " 'bbbbbbbbbbbbbbbb' 'cccccccccccccccc cccccccccccccbcc cccccccbccbbcbcb'\n",
      " 'cccccccccccccccc bbbbbbbbbbbbbbbb']\n"
     ]
    }
   ],
   "source": [
    "train_sax = np.array([SAX_window(ts, w=16, alpha=4, l = int(0.2*len(ts))+1 ) for ts in train['Music']])\n",
    "train_labels = np.array(train['Genre'])\n",
    "\n",
    "test_sax = np.array([SAX_window(ts, w=16, alpha=4, l = int(0.2*len(ts))+1 ) for ts in test['Music']])\n",
    "test_labels = np.array(test['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U9'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 107\u001b[0m\n\u001b[0;32m    104\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])            \u001b[38;5;66;03m# Labels\u001b[39;00m\n\u001b[0;32m    106\u001b[0m seql \u001b[38;5;241m=\u001b[39m SEQL(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m \u001b[43mseql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest feature:\u001b[39m\u001b[38;5;124m\"\u001b[39m, seql\u001b[38;5;241m.\u001b[39mbest_feature)\n",
      "Cell \u001b[1;32mIn[70], line 67\u001b[0m, in \u001b[0;36mSEQL.fit\u001b[1;34m(self, sequences, y)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Traverse features to find the best gradient\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature, idx \u001b[38;5;129;01min\u001b[39;00m feature_map\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     66\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m---> 67\u001b[0m         \u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(y \u001b[38;5;241m*\u001b[39m (X \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta))))\n\u001b[0;32m     68\u001b[0m     ) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n\u001b[0;32m     69\u001b[0m     gradient \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_regularization_gradient(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta[idx])\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Update best feature\u001b[39;00m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U9'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "# ChatGPT code \n",
    "\n",
    "class SEQL:\n",
    "    def __init__(self, C=1.0, alpha=0.5, convergence_threshold=1e-5, max_iterations=1000):\n",
    "        self.C = C\n",
    "        self.alpha = alpha\n",
    "        self.convergence_threshold = convergence_threshold\n",
    "        self.max_iterations = max_iterations\n",
    "        self.beta = None\n",
    "        self.best_feature = None\n",
    "\n",
    "    def _compute_regularization_gradient(self, beta_j):\n",
    "        \"\"\"Elastic-net gradient.\"\"\"\n",
    "        return self.alpha * np.sign(beta_j) + (1 - self.alpha) * beta_j\n",
    "\n",
    "    def _compute_loss_gradient(self, X, y, beta):\n",
    "        \"\"\"Compute gradients for all features.\"\"\"\n",
    "        margins = y * (X @ beta)\n",
    "        probabilities = 1 / (1 + np.exp(margins))\n",
    "        gradients = X.T @ (y * probabilities) / len(y)\n",
    "        return gradients\n",
    "\n",
    "    def _prune(self, prefix_gradient, current_best):\n",
    "        \"\"\"Prune if the bound indicates no improvement.\"\"\"\n",
    "        return np.abs(prefix_gradient) < current_best\n",
    "\n",
    "    def _expand_features(self, sequences, feature_map):\n",
    "        \"\"\"Iteratively expand features from unigrams.\"\"\"\n",
    "        expanded_features = set(feature_map.keys())\n",
    "        for seq in sequences:\n",
    "            for i in range(len(seq)):\n",
    "                for j in range(i + 1, len(seq) + 1):\n",
    "                    feature = seq[i:j]\n",
    "                    if ' ' in feature:\n",
    "                        continue  # Skip features containing spaces\n",
    "                    if feature not in expanded_features:\n",
    "                        feature_map[feature] = len(feature_map)\n",
    "                        expanded_features.add(feature)\n",
    "        return feature_map\n",
    "\n",
    "    def fit(self, sequences, y):\n",
    "        \"\"\"\n",
    "        Fit SEQL model.\n",
    "        - sequences: List of input sequences.\n",
    "        - y: Binary labels (-1, 1).\n",
    "        \"\"\"\n",
    "        # Start with unigrams\n",
    "        feature_map = {char: idx for idx, char in enumerate(set(''.join(sequences)))}\n",
    "        X = np.zeros((len(sequences), len(feature_map)))\n",
    "\n",
    "        # Build initial feature matrix\n",
    "        for i, seq in enumerate(sequences):\n",
    "            for feature in feature_map:\n",
    "                X[i, feature_map[feature]] = seq.count(feature)\n",
    "\n",
    "        num_features = X.shape[1]\n",
    "        self.beta = np.zeros(num_features)\n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            best_gradient = 0\n",
    "            best_feature = None\n",
    "\n",
    "            # Traverse features to find the best gradient\n",
    "            for feature, idx in feature_map.items():\n",
    "                gradient = np.sum(\n",
    "                    y * X[:, idx] * (1 / (1 + np.exp(y * (X @ self.beta))))\n",
    "                ) / len(y)\n",
    "                gradient += self.C * self._compute_regularization_gradient(self.beta[idx])\n",
    "\n",
    "                # Update best feature\n",
    "                if np.abs(gradient) > best_gradient:\n",
    "                    best_gradient = np.abs(gradient)\n",
    "                    best_feature = feature\n",
    "\n",
    "            # Stopping condition\n",
    "            if best_gradient < self.convergence_threshold:\n",
    "                print(\"Converged after\", iteration, \"iterations.\")\n",
    "                break\n",
    "\n",
    "            # Update selected feature\n",
    "            idx = feature_map[best_feature]\n",
    "            step_size = best_gradient  # Simplified; refine with line search if needed\n",
    "            self.beta[idx] -= step_size\n",
    "\n",
    "            # Expand feature map iteratively\n",
    "            feature_map = self._expand_features(sequences, feature_map)\n",
    "            new_X = np.zeros((len(sequences), len(feature_map)))\n",
    "            for i, seq in enumerate(sequences):\n",
    "                for feature in feature_map:\n",
    "                    new_X[i, feature_map[feature]] = seq.count(feature)\n",
    "            X = new_X\n",
    "            self.beta = np.zeros(len(feature_map))\n",
    "\n",
    "        self.best_feature = best_feature\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using the learned model.\"\"\"\n",
    "        return np.sign(X @ self.beta)\n",
    "\n",
    "# Example usage\n",
    "# Sequences should exclude spaces during preprocessing.\n",
    "sequences = [\"abc\", \"ab\", \"bc\"]  # Example sequences\n",
    "y = np.array([1, -1, 1])            # Labels\n",
    "\n",
    "seql = SEQL(C=1.0, alpha=0.5)\n",
    "seql.fit(train_sax, train_labels)\n",
    "print(\"Best feature:\", seql.best_feature)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
